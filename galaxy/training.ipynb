{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "plt = pyplot\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "import theano\n",
    "from numpy import float32\n",
    "import scipy\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from lasagne.nonlinearities import softmax, sigmoid, rectify\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "def load(f):\n",
    "    with open(f, \"rb\") as fa:\n",
    "        return pickle.load(fa)\n",
    "\n",
    "\n",
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "        \n",
    "        \n",
    "class FlipBatchIterator(BatchIterator):\n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(FlipBatchIterator, self).transform(Xb, yb)\n",
    "\n",
    "        # Flip half of the images in this batch at random:\n",
    "        bs = Xb.shape[0]\n",
    "        indices = np.random.choice(bs, bs / 2, replace=False)\n",
    "        Xb[indices] = Xb[indices, :, :, ::-1]\n",
    "        for i in range(len(Xb)):\n",
    "            n = np.random.randint(4)\n",
    "            Xb[i][0] = np.rot90(Xb[i][0], n)\n",
    "        \n",
    "        return Xb, yb\n",
    "    \n",
    "rotate = scipy.ndimage.interpolation.rotate\n",
    "def crop(image, dimx, dimy):\n",
    "    old_dimx, old_dimy = image.shape\n",
    "    fromx = (old_dimx - dimx)/2\n",
    "    tox = fromx + dimx\n",
    "    fromy = (old_dimy - dimy)/2\n",
    "    toy = fromy + dimy\n",
    "    return image[fromx:tox,fromy:toy]\n",
    "\n",
    "class BetterBatcher(BatchIterator):\n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(BetterBatcher, self).transform(Xb, yb)\n",
    "\n",
    "        # Flip half of the images in this batch at random:\n",
    "        bs = Xb.shape[0]\n",
    "        indices = np.random.choice(bs, bs / 2, replace=False)\n",
    "        Xb[indices] = Xb[indices, :, :, ::-1]\n",
    "        for i in range(len(Xb)):\n",
    "            n = np.random.randint(360)\n",
    "            Xb[i][0] = crop(rotate(Xb[i][0], n), 65, 65)\n",
    "        \n",
    "        return Xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = load(\"data/train_X_all.pickle\")\n",
    "y = pd.read_csv(\"data/training_solutions_rev1.csv\") \\\n",
    "    .drop('GalaxyID', 1).as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input             \t(None, 1, 65, 65)   \tproduces    4225 outputs\n",
      "  conv1             \t(None, 32, 63, 63)  \tproduces  127008 outputs\n",
      "  pool1             \t(None, 32, 32, 32)  \tproduces   32768 outputs\n",
      "  conv2             \t(None, 64, 31, 31)  \tproduces   61504 outputs\n",
      "  pool2             \t(None, 64, 16, 16)  \tproduces   16384 outputs\n",
      "  conv3             \t(None, 128, 15, 15) \tproduces   28800 outputs\n",
      "  pool3             \t(None, 128, 8, 8)   \tproduces    8192 outputs\n",
      "  hidden4           \t(None, 500)         \tproduces     500 outputs\n",
      "  hidden5           \t(None, 500)         \tproduces     500 outputs\n",
      "  output            \t(None, 37)          \tproduces      37 outputs\n",
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  0.029478\u001b[0m  |  \u001b[32m  0.027197\u001b[0m  |     1.083877  |             |  30.9s\n",
      "     2  |  \u001b[94m  0.026891\u001b[0m  |  \u001b[32m  0.025568\u001b[0m  |     1.051747  |             |  30.8s\n",
      "     3  |  \u001b[94m  0.024798\u001b[0m  |  \u001b[32m  0.023365\u001b[0m  |     1.061331  |             |  30.8s\n",
      "     4  |  \u001b[94m  0.023024\u001b[0m  |  \u001b[32m  0.021946\u001b[0m  |     1.049091  |             |  30.8s\n",
      "     5  |  \u001b[94m  0.021703\u001b[0m  |  \u001b[32m  0.021002\u001b[0m  |     1.033408  |             |  30.8s\n",
      "     6  |  \u001b[94m  0.020874\u001b[0m  |  \u001b[32m  0.019295\u001b[0m  |     1.081853  |             |  30.8s\n",
      "     7  |  \u001b[94m  0.019113\u001b[0m  |  \u001b[32m  0.018600\u001b[0m  |     1.027621  |             |  30.8s\n",
      "     8  |  \u001b[94m  0.018587\u001b[0m  |  \u001b[32m  0.018119\u001b[0m  |     1.025787  |             |  30.7s\n",
      "     9  |  \u001b[94m  0.018190\u001b[0m  |  \u001b[32m  0.017807\u001b[0m  |     1.021484  |             |  30.7s\n",
      "    10  |  \u001b[94m  0.017823\u001b[0m  |  \u001b[32m  0.017413\u001b[0m  |     1.023551  |             |  30.7s\n",
      "    11  |  \u001b[94m  0.017496\u001b[0m  |  \u001b[32m  0.017072\u001b[0m  |     1.024796  |             |  30.7s\n",
      "    12  |  \u001b[94m  0.017188\u001b[0m  |  \u001b[32m  0.016826\u001b[0m  |     1.021526  |             |  30.7s\n",
      "    13  |  \u001b[94m  0.016895\u001b[0m  |  \u001b[32m  0.016387\u001b[0m  |     1.030995  |             |  30.8s\n",
      "    14  |  \u001b[94m  0.016575\u001b[0m  |  \u001b[32m  0.016332\u001b[0m  |     1.014926  |             |  30.7s\n",
      "    15  |  \u001b[94m  0.016306\u001b[0m  |  \u001b[32m  0.015760\u001b[0m  |     1.034649  |             |  30.7s\n",
      "    16  |  \u001b[94m  0.016043\u001b[0m  |  \u001b[32m  0.015660\u001b[0m  |     1.024442  |             |  30.7s\n",
      "    17  |  \u001b[94m  0.015797\u001b[0m  |  \u001b[32m  0.015315\u001b[0m  |     1.031470  |             |  30.7s\n",
      "    18  |  \u001b[94m  0.015576\u001b[0m  |  \u001b[32m  0.015146\u001b[0m  |     1.028419  |             |  30.6s\n",
      "    19  |  \u001b[94m  0.015360\u001b[0m  |  \u001b[32m  0.014972\u001b[0m  |     1.025925  |             |  29.9s\n",
      "    20  |  \u001b[94m  0.015168\u001b[0m  |  \u001b[32m  0.014822\u001b[0m  |     1.023329  |             |  29.9s\n",
      "    21  |  \u001b[94m  0.015002\u001b[0m  |    0.014835  |     1.011226  |             |  29.9s\n",
      "    22  |  \u001b[94m  0.014836\u001b[0m  |  \u001b[32m  0.014624\u001b[0m  |     1.014512  |             |  29.9s\n",
      "    23  |  \u001b[94m  0.014704\u001b[0m  |  \u001b[32m  0.014535\u001b[0m  |     1.011596  |             |  29.9s\n",
      "    24  |  \u001b[94m  0.014587\u001b[0m  |    0.014656  |     0.995327  |             |  30.0s\n",
      "    25  |  \u001b[94m  0.014450\u001b[0m  |  \u001b[32m  0.014465\u001b[0m  |     0.998985  |             |  29.9s\n",
      "    26  |  \u001b[94m  0.014351\u001b[0m  |  \u001b[32m  0.014275\u001b[0m  |     1.005356  |             |  29.9s\n",
      "    27  |  \u001b[94m  0.014236\u001b[0m  |  \u001b[32m  0.014241\u001b[0m  |     0.999620  |             |  29.9s\n",
      "    28  |  \u001b[94m  0.014138\u001b[0m  |  \u001b[32m  0.014053\u001b[0m  |     1.006008  |             |  29.9s\n",
      "    29  |  \u001b[94m  0.014041\u001b[0m  |    0.014069  |     0.997992  |             |  29.9s\n",
      "    30  |  \u001b[94m  0.013946\u001b[0m  |    0.014100  |     0.989095  |             |  29.9s\n",
      "    31  |  \u001b[94m  0.013863\u001b[0m  |  \u001b[32m  0.013965\u001b[0m  |     0.992654  |             |  29.9s\n",
      "    32  |  \u001b[94m  0.013771\u001b[0m  |    0.013967  |     0.986028  |             |  29.9s\n",
      "    33  |  \u001b[94m  0.013688\u001b[0m  |  \u001b[32m  0.013907\u001b[0m  |     0.984249  |             |  29.9s\n",
      "    34  |  \u001b[94m  0.013619\u001b[0m  |  \u001b[32m  0.013696\u001b[0m  |     0.994411  |             |  29.9s\n",
      "    35  |  \u001b[94m  0.013562\u001b[0m  |    0.013808  |     0.982135  |             |  29.8s\n",
      "    36  |  \u001b[94m  0.013496\u001b[0m  |  \u001b[32m  0.013608\u001b[0m  |     0.991779  |             |  29.9s\n",
      "    37  |  \u001b[94m  0.013420\u001b[0m  |    0.013643  |     0.983668  |             |  29.9s\n",
      "    38  |  \u001b[94m  0.013335\u001b[0m  |  \u001b[32m  0.013544\u001b[0m  |     0.984591  |             |  29.9s\n",
      "    39  |  \u001b[94m  0.013282\u001b[0m  |  \u001b[32m  0.013377\u001b[0m  |     0.992949  |             |  29.9s\n",
      "    40  |  \u001b[94m  0.013230\u001b[0m  |    0.013405  |     0.986993  |             |  29.8s\n",
      "    41  |  \u001b[94m  0.013165\u001b[0m  |    0.013451  |     0.978743  |             |  29.9s\n",
      "    42  |  \u001b[94m  0.013108\u001b[0m  |  \u001b[32m  0.013339\u001b[0m  |     0.982681  |             |  29.9s\n",
      "    43  |  \u001b[94m  0.013050\u001b[0m  |  \u001b[32m  0.013245\u001b[0m  |     0.985314  |             |  29.9s\n",
      "    44  |  \u001b[94m  0.013005\u001b[0m  |  \u001b[32m  0.013208\u001b[0m  |     0.984619  |             |  29.9s\n",
      "    45  |  \u001b[94m  0.012940\u001b[0m  |    0.013246  |     0.976893  |             |  29.8s\n",
      "    46  |  \u001b[94m  0.012875\u001b[0m  |  \u001b[32m  0.013179\u001b[0m  |     0.976932  |             |  29.8s\n",
      "    47  |  \u001b[94m  0.012834\u001b[0m  |  \u001b[32m  0.013018\u001b[0m  |     0.985855  |             |  29.9s\n",
      "    48  |  \u001b[94m  0.012790\u001b[0m  |  \u001b[32m  0.012985\u001b[0m  |     0.984968  |             |  30.0s\n",
      "    49  |  \u001b[94m  0.012745\u001b[0m  |    0.013004  |     0.980072  |             |  29.9s\n",
      "    50  |  \u001b[94m  0.012692\u001b[0m  |  \u001b[32m  0.012973\u001b[0m  |     0.978327  |             |  29.9s\n",
      "    51  |  \u001b[94m  0.012636\u001b[0m  |  \u001b[32m  0.012916\u001b[0m  |     0.978319  |             |  29.9s\n",
      "    52  |  \u001b[94m  0.012604\u001b[0m  |  \u001b[32m  0.012913\u001b[0m  |     0.976106  |             |  29.9s\n",
      "    53  |  \u001b[94m  0.012548\u001b[0m  |  \u001b[32m  0.012816\u001b[0m  |     0.979086  |             |  29.8s\n",
      "    54  |  \u001b[94m  0.012532\u001b[0m  |  \u001b[32m  0.012716\u001b[0m  |     0.985502  |             |  29.9s\n",
      "    55  |  \u001b[94m  0.012472\u001b[0m  |  \u001b[32m  0.012703\u001b[0m  |     0.981842  |             |  29.9s\n",
      "    56  |  \u001b[94m  0.012423\u001b[0m  |    0.012715  |     0.977055  |             |  30.0s\n",
      "    57  |  \u001b[94m  0.012409\u001b[0m  |  \u001b[32m  0.012658\u001b[0m  |     0.980281  |             |  29.9s\n",
      "    58  |  \u001b[94m  0.012373\u001b[0m  |  \u001b[32m  0.012601\u001b[0m  |     0.981924  |             |  29.9s\n",
      "    59  |  \u001b[94m  0.012331\u001b[0m  |    0.012631  |     0.976284  |             |  29.8s\n",
      "    60  |  \u001b[94m  0.012281\u001b[0m  |  \u001b[32m  0.012497\u001b[0m  |     0.982677  |             |  29.9s\n",
      "    61  |  \u001b[94m  0.012236\u001b[0m  |    0.012502  |     0.978751  |             |  29.9s\n",
      "    62  |  \u001b[94m  0.012216\u001b[0m  |  \u001b[32m  0.012392\u001b[0m  |     0.985759  |             |  29.9s\n",
      "    63  |  \u001b[94m  0.012181\u001b[0m  |    0.012415  |     0.981112  |             |  29.9s\n",
      "    64  |  \u001b[94m  0.012147\u001b[0m  |  \u001b[32m  0.012368\u001b[0m  |     0.982109  |             |  29.9s\n",
      "    65  |  \u001b[94m  0.012110\u001b[0m  |  \u001b[32m  0.012282\u001b[0m  |     0.985980  |             |  29.9s\n",
      "    66  |  \u001b[94m  0.012052\u001b[0m  |  \u001b[32m  0.012258\u001b[0m  |     0.983133  |             |  29.9s\n",
      "    67  |    0.012054  |  \u001b[32m  0.012175\u001b[0m  |     0.990052  |             |  29.9s\n",
      "    68  |  \u001b[94m  0.011996\u001b[0m  |    0.012188  |     0.984222  |             |  29.9s\n",
      "    69  |  \u001b[94m  0.011984\u001b[0m  |  \u001b[32m  0.012122\u001b[0m  |     0.988638  |             |  29.9s\n",
      "    70  |  \u001b[94m  0.011939\u001b[0m  |  \u001b[32m  0.012074\u001b[0m  |     0.988794  |             |  29.9s\n",
      "    71  |  \u001b[94m  0.011910\u001b[0m  |  \u001b[32m  0.012051\u001b[0m  |     0.988306  |             |  29.9s\n",
      "    72  |  \u001b[94m  0.011877\u001b[0m  |  \u001b[32m  0.012051\u001b[0m  |     0.985561  |             |  29.9s\n",
      "    73  |  \u001b[94m  0.011851\u001b[0m  |  \u001b[32m  0.011964\u001b[0m  |     0.990488  |             |  29.9s\n",
      "    74  |  \u001b[94m  0.011833\u001b[0m  |  \u001b[32m  0.011955\u001b[0m  |     0.989831  |             |  30.0s\n",
      "    75  |  \u001b[94m  0.011801\u001b[0m  |    0.012009  |     0.982667  |             |  30.2s\n",
      "    76  |  \u001b[94m  0.011758\u001b[0m  |  \u001b[32m  0.011934\u001b[0m  |     0.985267  |             |  30.1s\n",
      "    77  |    0.011760  |  \u001b[32m  0.011894\u001b[0m  |     0.988696  |             |  30.1s\n",
      "    78  |  \u001b[94m  0.011661\u001b[0m  |  \u001b[32m  0.011784\u001b[0m  |     0.989507  |             |  30.2s\n",
      "    79  |  \u001b[94m  0.011615\u001b[0m  |    0.011786  |     0.985518  |             |  30.2s\n",
      "    80  |  \u001b[94m  0.011583\u001b[0m  |  \u001b[32m  0.011707\u001b[0m  |     0.989387  |             |  30.2s\n",
      "    81  |  \u001b[94m  0.011528\u001b[0m  |  \u001b[32m  0.011698\u001b[0m  |     0.985478  |             |  30.2s\n",
      "    82  |  \u001b[94m  0.011521\u001b[0m  |  \u001b[32m  0.011650\u001b[0m  |     0.988909  |             |  30.0s\n",
      "    83  |  \u001b[94m  0.011503\u001b[0m  |  \u001b[32m  0.011627\u001b[0m  |     0.989342  |             |  30.0s\n",
      "    84  |  \u001b[94m  0.011456\u001b[0m  |  \u001b[32m  0.011615\u001b[0m  |     0.986387  |             |  30.0s\n",
      "    85  |  \u001b[94m  0.011437\u001b[0m  |    0.011627  |     0.983589  |             |  30.1s\n",
      "    86  |  \u001b[94m  0.011423\u001b[0m  |  \u001b[32m  0.011598\u001b[0m  |     0.984914  |             |  30.0s\n",
      "    87  |  \u001b[94m  0.011395\u001b[0m  |  \u001b[32m  0.011547\u001b[0m  |     0.986836  |             |  29.9s\n",
      "    88  |  \u001b[94m  0.011369\u001b[0m  |    0.011609  |     0.979339  |             |  29.8s\n",
      "    89  |  \u001b[94m  0.011327\u001b[0m  |  \u001b[32m  0.011521\u001b[0m  |     0.983162  |             |  29.9s\n",
      "    90  |  \u001b[94m  0.011301\u001b[0m  |  \u001b[32m  0.011493\u001b[0m  |     0.983285  |             |  29.8s\n",
      "    91  |  \u001b[94m  0.011275\u001b[0m  |    0.011518  |     0.978871  |             |  30.0s\n",
      "    92  |  \u001b[94m  0.011248\u001b[0m  |    0.011517  |     0.976653  |             |  29.9s\n",
      "    93  |  \u001b[94m  0.011232\u001b[0m  |  \u001b[32m  0.011466\u001b[0m  |     0.979657  |             |  29.9s\n",
      "    94  |  \u001b[94m  0.011197\u001b[0m  |  \u001b[32m  0.011464\u001b[0m  |     0.976725  |             |  29.9s\n",
      "    95  |  \u001b[94m  0.011179\u001b[0m  |  \u001b[32m  0.011369\u001b[0m  |     0.983229  |             |  29.9s\n",
      "    96  |  \u001b[94m  0.011147\u001b[0m  |  \u001b[32m  0.011362\u001b[0m  |     0.981069  |             |  29.9s\n",
      "    97  |  \u001b[94m  0.011127\u001b[0m  |    0.011375  |     0.978134  |             |  29.9s\n",
      "    98  |    0.011141  |    0.011455  |     0.972583  |             |  29.9s\n",
      "    99  |  \u001b[94m  0.011107\u001b[0m  |    0.011420  |     0.972557  |             |  29.9s\n",
      "   100  |  \u001b[94m  0.011100\u001b[0m  |    0.011394  |     0.974208  |             |  29.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=<function tensor4 at 0x7f1ba79bf140>,\n",
       "     batch_iterator_test=<__main__.FlipBatchIterator object at 0x7f1b4cdfbe50>,\n",
       "     batch_iterator_train=<__main__.FlipBatchIterator object at 0x7f1b8d0f9550>,\n",
       "     conv1_filter_size=(3, 3), conv1_num_filters=32,\n",
       "     conv2_filter_size=(2, 2), conv2_num_filters=64,\n",
       "     conv3_filter_size=(2, 2), conv3_num_filters=128, eval_size=0.2,\n",
       "     hidden4_num_units=500, hidden5_num_units=500,\n",
       "     input_shape=(None, 1, 65, 65),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv3', <class..., <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<class 'lasagne.objectives.Objective'>,\n",
       "     objective_loss_function=<function mse at 0x7f1b9a94f758>,\n",
       "     on_epoch_finished=[<__main__.AdjustVariable object at 0x7f1b4cdfbe90>, <__main__.AdjustVariable object at 0x7f1b4cdfbed0>],\n",
       "     on_training_finished=(),\n",
       "     output_nonlinearity=<function rectify at 0x7f1b9a919a28>,\n",
       "     output_num_units=37, pool1_ds=(2, 2), pool2_ds=(2, 2),\n",
       "     pool3_ds=(2, 2), regression=True,\n",
       "     update=<function nesterov_momentum at 0x7f1b9a94fde8>,\n",
       "     update_learning_rate=<CudaNdarrayType(float32, scalar)>,\n",
       "     update_momentum=<CudaNdarrayType(float32, scalar)>,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(float32, matrix))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3 = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 65, 65),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_ds=(2, 2),\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_ds=(2, 2),\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_ds=(2, 2),\n",
    "    hidden4_num_units=500, hidden5_num_units=500,\n",
    "    output_num_units=37, output_nonlinearity=rectify,\n",
    "\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
    "    batch_iterator_test=FlipBatchIterator(batch_size=128),\n",
    "    regression=True,\n",
    "    max_epochs=100,\n",
    "    verbose=1,\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "net3.fit(X, y)\n",
    "# with open(\"net3.pickle\", \"wb\") as out:\n",
    "#     pickle.dump(net3, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  0.011213\u001b[0m  |  \u001b[32m  0.011504\u001b[0m  |     0.974720  |             |  29.9s\n",
      "     2  |    0.011488  |    0.011753  |     0.977436  |             |  29.9s\n",
      "     3  |    0.011314  |    0.011750  |     0.962965  |             |  29.9s\n",
      "     4  |    0.011252  |    0.011647  |     0.966098  |             |  29.9s\n",
      "     5  |    0.011226  |    0.011539  |     0.972925  |             |  29.9s\n",
      "     6  |  \u001b[94m  0.011189\u001b[0m  |    0.011551  |     0.968657  |             |  29.9s\n",
      "     7  |  \u001b[94m  0.011149\u001b[0m  |  \u001b[32m  0.011478\u001b[0m  |     0.971405  |             |  29.9s\n",
      "     8  |  \u001b[94m  0.011118\u001b[0m  |  \u001b[32m  0.011451\u001b[0m  |     0.970908  |             |  29.9s\n",
      "     9  |  \u001b[94m  0.011083\u001b[0m  |  \u001b[32m  0.011381\u001b[0m  |     0.973846  |             |  29.9s\n",
      "    10  |  \u001b[94m  0.011071\u001b[0m  |    0.011436  |     0.968114  |             |  29.9s\n",
      "    11  |  \u001b[94m  0.011036\u001b[0m  |    0.011397  |     0.968332  |             |  29.9s\n",
      "    12  |  \u001b[94m  0.011031\u001b[0m  |  \u001b[32m  0.011277\u001b[0m  |     0.978215  |             |  29.9s\n",
      "    13  |  \u001b[94m  0.011011\u001b[0m  |    0.011336  |     0.971320  |             |  29.9s\n",
      "    14  |  \u001b[94m  0.010981\u001b[0m  |    0.011422  |     0.961312  |             |  29.9s\n",
      "    15  |  \u001b[94m  0.010948\u001b[0m  |    0.011337  |     0.965608  |             |  29.9s\n",
      "    16  |  \u001b[94m  0.010940\u001b[0m  |    0.011365  |     0.962636  |             |  29.9s\n",
      "    17  |  \u001b[94m  0.010921\u001b[0m  |  \u001b[32m  0.011211\u001b[0m  |     0.974179  |             |  29.9s\n",
      "    18  |  \u001b[94m  0.010899\u001b[0m  |    0.011239  |     0.969806  |             |  29.9s\n",
      "    19  |  \u001b[94m  0.010873\u001b[0m  |    0.011227  |     0.968512  |             |  29.9s\n",
      "    20  |  \u001b[94m  0.010867\u001b[0m  |    0.011266  |     0.964567  |             |  29.9s\n",
      "    21  |  \u001b[94m  0.010846\u001b[0m  |  \u001b[32m  0.011175\u001b[0m  |     0.970550  |             |  29.9s\n",
      "    22  |  \u001b[94m  0.010828\u001b[0m  |  \u001b[32m  0.011151\u001b[0m  |     0.970995  |             |  29.9s\n",
      "    23  |  \u001b[94m  0.010805\u001b[0m  |  \u001b[32m  0.011114\u001b[0m  |     0.972226  |             |  29.9s\n",
      "    24  |  \u001b[94m  0.010790\u001b[0m  |    0.011126  |     0.969714  |             |  29.9s\n",
      "    25  |  \u001b[94m  0.010757\u001b[0m  |    0.011124  |     0.967032  |             |  29.9s\n",
      "    26  |  \u001b[94m  0.010754\u001b[0m  |  \u001b[32m  0.011067\u001b[0m  |     0.971698  |             |  29.9s\n",
      "    27  |  \u001b[94m  0.010738\u001b[0m  |  \u001b[32m  0.011036\u001b[0m  |     0.972936  |             |  29.9s\n",
      "    28  |  \u001b[94m  0.010711\u001b[0m  |  \u001b[32m  0.011030\u001b[0m  |     0.971067  |             |  29.9s\n",
      "    29  |  \u001b[94m  0.010690\u001b[0m  |    0.011088  |     0.964114  |             |  29.9s\n",
      "    30  |  \u001b[94m  0.010686\u001b[0m  |  \u001b[32m  0.010977\u001b[0m  |     0.973508  |             |  29.9s\n"
     ]
    }
   ],
   "source": [
    "with open(\"net3.pickle\", \"wb\") as out:\n",
    "    pickle.dump(net3, out)\n",
    "    \n",
    "net3.max_epochs=30\n",
    "net3.fit(X, y)\n",
    "\n",
    "with open(\"net3.130.pickle\", \"wb\") as out:\n",
    "    pickle.dump(net3, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecnGW5//HPtWmkFwgJhIQ0ShCkBGkSCCBF5AAqxQIK\n",
       "KHj0Z+F4pB5gMiKCeERAiiBKDlUMoIAiUqRLDQQSDAkJISGQQhLSy2az1++P+5nJZNndzLZ55p79\n",
       "vl+vfTH7zMwz3wm7c+1dnvs2d0dERKQYVWkHEBGReKhoiIhI0VQ0RESkaCoaIiJSNBUNEREpmoqG\n",
       "iIgUrWPaAVrCzDRfWESkGdzdmvO8qItG4Ae683zaKZrDzMa5+7i0czSX8qcn5uyg/GlryR/cldA9\n",
       "dWLaAVpgaNoBWmho2gFaaGjaAVpgaNoBWmho2gFaaGjaAdJSCUVjWNoBRETaCxWNdI1PO0ALjU87\n",
       "QAuNTztAC4xPO0ALjU87QAuNTztAWizmtadCv5yvBHq5E+8bEREpITPz5g6EV0JLowewZdohmsPM\n",
       "xqadoSWUPz0xZ4fWzW9mrq+Gv1rr3zmnAmZPAWFQalHaIUQkHc39q7m5zGysuz9VytdsjrYoGpXQ\n",
       "PQVwkjsT0s4jIqXXkq6WStfQv017756CuAfDRUSioaKRIvVLpyvm/DFnB+WPmYqGiEgZM7Mbzeyi\n",
       "tHPkVMqYxjR3dk47j4iUXrmPaZjZe8AZ7v7PFF5bYxoNGGpWMe9FRCqLA/V+QJtZdDNYK+WDtgsw\n",
       "MO0QTRV7v6jypyfm7NB+8pvZ7cAQ4CEzW2Fm55hZrZmdYWazgceTx00ws3lmttTMnjazXQrOMd7M\n",
       "Ls29rpnNNbMfm9kCM/vQzE5r9TfYiEopGqBxDRGphxneWl9NfW13PxWYAxzj7j2BPyV3HQTsDByZ\n",
       "fP83YCTQH3gNuLPwNMlXzgCgF7At8C3gejPr3dRszaWikaIYLg5qjPKnJ+bs0K7z57qpxrn7Gndf\n",
       "l5xvvLuvcvf1QBbY3cx61vM8gPXAT919g7v/HVgJ7NTMPE0Wf9HouiR3K7qiISLt1vu5G2ZWZWZX\n",
       "mNkMM1sGzEru2qqB5y5299qC71cTllMqifiLxuibc7eGppiiWdpLv265ijl/zNmhtPndsdb6amb+\n",
       "+rq1Co99HTgWOMzde7PxD2Br4PGpir9oDHw9d0stDREpRwuAEY3c3wNYBywxs+7Az+vcbzQw+yoN\n",
       "8ReNbeItGu24X7csxJw/5uzQ7vJfDlxkZkuAL/PJVsNtwGzgA2AK8EKdx9QdCE+11RH/xX3jgJ8v\n",
       "h+qeG4Cu7qxPOZaIlFC5X9yXJl3c15ABbwJ0ALZPOUmTqF86XTHnjzk7KH/MKqNobOyi2jHNGCIi\n",
       "la4yisbGwfAd0ozRVO2sX7fsxJw/5uyg/DGrjKKxTZxFQ0QkNpVRNPq/BR2qIbKiEXu/qPKnJ+bs\n",
       "oPwxq4yi0bEatpoKkRUNEZHYVMaUW4C/3AqTTqsFurmzLsVYIlJCmnLbME25bUwYDK8ChqecRESk\n",
       "YlVO0YhwMDz2flHlT0/M2UH5izm/mRUuajjFzA4q5rFtLbpdoxo0cBLJBlnRFA0RkWK4+65pZ8ip\n",
       "hJbGUgC6rIAe8yGilkbsc72VPz0xZwflj1klFI1387f6zoKIioaIVDYzO8/MJtQ5dk3ydZqZ/dvM\n",
       "lpvZTDM7q5HzvGdmhyW3uyZbwC4xs7eAz7Tx29hEJXRPzQL2AqDvu/D+AdEUDTMbG/NfLMqfnpiz\n",
       "Q2nzW9ZabYqoZ8KMoybkvxu4xMx6uPtKM+sAnAgcT9hk6QvuPisZr/i7mb3i7q/Xc57ClW4zhFW9\n",
       "hxOWVX+EEq58W1ktjT6zAAab0S21NCIiCXefQ9jz+4vJoUOB1e7+srs/7O6zksc9AzwKjCnitCcC\n",
       "l7n7UnefC1xDCffbqISiMSt/q2++fjS24UnZiPkvRVD+NMWcHdpd/ruArya3vwbcCWBmnzezF81s\n",
       "sZl9DBwNbFnE+balYLtYYE4TsrRYJXRP1R3TgDCuMTmNMCJSXnJdSim6F/iVmQ0idEvtZ2ZdgPuA\n",
       "U4AH3H2Dmf2Z4loM84AhwNTk+yFtkLlBldXS6JO/uVMqSZpIc9XTFXP+mLND+8rv7h8BTwHjgXfd\n",
       "fRrQOflaBNSa2eeBI4o85Z+AC8ysj5ltB/yg+OQtVwlFYza5QaDe7+cWLtw5zUAiInXcBRyW/Bd3\n",
       "XwH8kFAAlhC6rx6o85yGBrezhM+9WYRB8NsaeWyri37tKXc3y9r7wHYAXPsOLBn5ijv7pJtOREpB\n",
       "a081TGtPNazuYPjOZqWbTSAi0l5UStGoO+22J2GGQVlrT/265Sjm/DFnB+WPWaUUjfqm3Y5KJYmI\n",
       "SAWrlKJR37Tbsh8Mb2dz1ctOzPljzg7KH7NKKRr1TbtVS0NEpJVVStEoaGnkb5Z9SyP2flHlT0/M\n",
       "2UH5Y1YJV4QDzAfWAV3otgS6LIN1vdXSEGknzFpvUcImvGapX7IsVMR1GgCWtankWhe/fR3m7wHQ\n",
       "x51l6SUUESk/uk4jqG9co+y7qEREYlJJRWNm/tZWb+dulXUXVez9osqfnpizg/LHrJKKxsZVbQe+\n",
       "kbulloaISCuqpKIxKX9rYP5mWbc0Yp/rrfzpiTk7KH/MKqloTAFqAdhyOnRaBbBbmoFERCpNxRQN\n",
       "z/hqYBoA5jBgMsAwM/qlmasxsfeLKn96Ys4Oyh+ziikaifq6qPZKJYmISAWqtKLxev7WxqIxOpUk\n",
       "RYi9X1T50xNzdlD+mFVa0ShoaeTrR9kWDRGR2FRa0cjPtWXAm1BVA2VcNGLvF1X+9MScHZQ/ZhVV\n",
       "NDzjC4EPAei0Fvq9AzDcjL5p5hIRqRQVVTQS0QyGx94vqvzpiTk7KH/M2kvRKNsuKhGRmFR20dim\n",
       "vAfDY+8XVf70xJwdlD9mlVg0JuZvDf4XVK2HMi0aIiKxqZj9NPLHsmaEnfyGAvCHZ2DOGIC+7iwt\n",
       "dUYRkXKj/TQKeMYdeDx/YHj+5sFp5BERqSQVVzQSj+Vvjcjf/I9UkjQi9n5R5U9PzNlB+WNWqUXj\n",
       "n0Dodxv0ctgzHI4xq9j3KyJSEhU3ppG/L2sTyV2fcfcDMO1YgP3ceal0CUVEyo/GNOpXMK6R76I6\n",
       "NpUkIiIVopKLxsZxjY2D4WU1rhF7v6jypyfm7KD8MavkovE8sA6A/m9Dzw8AdjNLpuKKiEiTVWzR\n",
       "8IyvAV7OH9h6Su5W2bQ2Yl+/RvnTE3N2UP6YVWzRSLyTv9VvRu7WPqkkERGpAJVeNPKVgn4zc7eG\n",
       "p5KkHrH3iyp/emLODsofs0ovGvlKUdDSKJuiISISm4q9TgPAsrYXuQUMF+4CN7yVu6u7O6vbPqGI\n",
       "SPnRdRoNK2xpOFab+25YKmlERCJX0UXDM74MWARAx2pLpt0CjEgrU6HY+0WVPz0xZwflj1lFF41E\n",
       "WQ+Gi4jEpD0UjbIdDI99rrfypyfm7KD8MWsPRWNjS6OvWhoiIi0RfdEws3Gb6V8s25ZG7P2iyp+e\n",
       "mLOD8qfFzMaa2biWnCP6ouHu4zbTVKxvTGOY9tYQkfbG3Z9y93EtOUdFX6cBYFnbGlgAwLoezuXL\n",
       "DQxgO3c+aOy5IiKVSNdpNO4jYAUAXVYa3T/KHS+LLioRkZhUfNHwjDtlOhgea79ojvKnJ+bsoPwx\n",
       "q/iikSjbwXARkZi0l6JRMBhePkUj9rneyp+emLOD8sesvRSNaflb2z+bu5V60RARiU17KRr/AMI0\n",
       "se2fhm6LAEaa0azZA60l9n5R5U9PzNlB+WPWLoqGZ3we8C8AqmphpwcBtgbGpBhLRCQ67aJoJO7P\n",
       "3xp1X+7W91NJkoi9X1T50xNzdlD+mLWnovHn/K3hj0OXZQBfMmNQaolERCLTboqGZ3wW8DoAHath\n",
       "h4cBOgDfSStT7P2iyp+emLOD8ses3RSNREEXVf7mWWZ0TiWNiEhkKn7tqU0en7VdgLBR+PotnKvm\n",
       "Gmu2BDjTnVvaJqWISHnR2lPFmwpMAqDTWmPv3+aOZ83ollYoEZFYtKuikaxDdVX+wL7X1tJhHcC2\n",
       "wNmlzhN7v6jypyfm7KD8MWtXRSNxD/AhAD0WVrHbXbnj55vRP61QIiIxaFdjGvnnZe1c4BcALNpx\n",
       "Hde93SXZY+M6d37QuilFRMqLxjSa7mZgJQBbTe/Cpybkjn/XjF3SCiUiUu7aZdHwjC8Ffpc/cMxZ\n",
       "6+m+EMJ1G1eXak2q2PtFlT89MWcH5Y9ZuywaiZ8CcwHouqwTX/guyZqGhwPHpBdLRKR8bXZMw8zO\n",
       "Bm4FlgO3AHsB57v7P9o+XuNa0i8HYFk7grACbnDfHTD56xA2bdrVnbUtDikiUmbaekzjDHdfBhwB\n",
       "9ANOBa5ozouVG8/4o8BN+QNHnON0XAMwArgkpVgiImWrmKKRq0ZfAG539yltmCcN5wDzAeg5z9jn\n",
       "+tzxc83Ysy1fOPZ+UeVPT8zZQfljVkzRmGhmjwJHA/8ws15AbdvGKh3P+Arg0vyBgy6tSVbA7QD8\n",
       "wYxOKUUTESk7xYxpVAF7AjPdfamZbQkMcvc3SxGwMS0d08ifJ2udgbeBYQA8fVENT17aMbn7AvfK\n",
       "6I4TEYG2H9PYH5iWFIxTgYuAZc15sXLlGa8GMvkDn71yAz3m5b4bZ8ZOaeQSESk3xRSN3wKrzGx3\n",
       "4MfADOC2Nk2VjruAMF7TsboLX/jukuR4F+AWs9afnhx7v6jypyfm7KD8MSvmg7DGQx/W8cD17n49\n",
       "0LNtY5WeZ3wD8F/5A6Me6MeQZzYk3x0IfDeNXCIi5aSYMY1ngEeA04ExwEfAJHffre3jNa61xjQ2\n",
       "OWfWJgAnALB824VcPXtrajsCrAJ2d2dma76eiEiptfWYxsnAOsL1GvOBQcAvm/NikfhvYDUAvT7c\n",
       "mkMuXpgc7w6MN6NDWsFERNK22aLh7vOAO4E+ZnYMsNbdK3FMAwDP+BzgsvyBA6/ozw5/zU0xPpDC\n",
       "LqwWir1fVPnTE3N2UP6YbbZomNlJwEvAicBJwMtmdmJbB0vZL4FnADCMk09Yz1Zv5+67zIyd0wom\n",
       "IpKmYsY03gQ+5+4Lk+/7A0+4+6dLkK9RbTGmkT931rYGXgGGAPDRqNVc/1a35AL5p4BD3Yl3MxIR\n",
       "abfaekzDCIPfOYuhNEuHp8kzvpAwYywsWth/ajeGP5brphoLnJJOMhGR9BRTNB4hLB9ympmdDjwM\n",
       "/L1tY5UHz/jrFO67ceRPZhfc/Ssz+rXk/LH3iyp/emLODsofs2KKxrmElWB3B3YDbnL3c9s0VXm5\n",
       "hmSjDQZMHsaASfOT4/2Bq9IKJSKShna5R3iTXydr9wNfBGDhpx7jhimHF9z9FXfuaesMIiKtpU3G\n",
       "NMxspZmtaOBrefPjRmlji6L/W2M55chZjLoPrBbgJjOGphVMRKSUGiwa7t7D3Xs28NWrlCHLwPOE\n",
       "mVRgdGLko8M4+QQ49CKA3sCdZnRs5Pn1ir1fVPnTE3N2UP6Ytec9wovmGXfgR8AHm9yx1y1gGwAO\n",
       "IKz+KyJS0TSm0ZTXy1oVMBp4EBgIwPh/wnuHQNiY6mB3nitVHhGR5mjr6zQk4Rmv9Yy/AtyXPzj6\n",
       "5g+TW1WEbqq+aWQTESkFFY3mmZC/9ak/dcJqPk6+G0LYIraoCh57v6jypyfm7KD8MVPRaJ7ngAUA\n",
       "VNX25+CfFl6vcTxhsyoRkYqjMY3mvnbWbmDjxkzXMc43EAbLATYAYzW+ISLlSGMa6ZhQcPtrXNDz\n",
       "Gah9Mfm+A3CvGYNTyCUi0mZUNJrvWXJdVNCPLivv4396OF0X5/YWHwA8ZEaPhk4Qe7+o8qcn5uyg\n",
       "/DFT0Wgmz3gNcBqwIn+w05r9OXOfF4H1yZHdgTvM9O8sIpVBYxotzZC1/kAG+H/JoVrumXAxU0+4\n",
       "rOBhV7pzXunTiYh8Uks+O1U0Woll7VEgt5DhfYzzWcBPCh5yujvjSx5MRKQODYSXhwsLbn+ZC3tM\n",
       "AP5acOxmM8YWPiH2flHlT0/M2UH5Y6ai0Uo8469SeKV451W/5dhvfR94MznSCXjQjNEpxBMRaRXq\n",
       "nmpFlrWdgSmEKbcA/+bJ7Ok8fckD5NaqgkXAGHfeTiOjiIi6p8qEZ/xt4HvkdvqDXTgkcw8HXXoG\n",
       "kFtqZCvgn2bskkZGEZGWUNFoZZ7xm4GvAzXJoaEcesmtHHLxD4BVybFtgGfMTv9OGhlbS+z9ujHn\n",
       "jzk7KH/MVDTagGf8buA4YE1yaAAH/+x6jvjJecDK5NiWcMpVZhycSkgRkWbQmEYbsqwdSJhB1Ts5\n",
       "tIYpJ5/PvX/MAP2SY2uBE9z5WxoZRaT90XUaZcyytjvwD8KyIgA1rO31KkuHjWbxjp34642wZssa\n",
       "4ExdxyEipaCB8DLmGX8DOBB4LznUkS2W78fANzrRbQKc/GWoWt8RuNWMm83YIrWwTRR7v27M+WPO\n",
       "DsofMxWNEvCMzyAUjrc+cefQp+HzP8x9dybwkh308y9Y1vYrXUIRkeKoe6qELGvdCEuNrAMOAi7I\n",
       "3/nC2fD8eXDA/8IBvwrHaquuo6r2h56J+H+SiJQdjWlEyLJmwJ3AVxt94Ootf+a/WHRxSUKJSLug\n",
       "MY0Iecad/2U88FSjD+y2+CI7fewlpcjUVLH368acP+bsoPwxU9FI00qqgcOArwDTAXDW8upZj/Du\n",
       "oRsfN/j5rO1904Nm+Wm6IiKpUPdUmbCsdQT2A2Z6xufZ1m99jRO+cjsDpoTCXt0d/u/xZXyw35nu\n",
       "m2w1KyLSJBrTqFC272/GcNBlj9JjQZiGW90d3j8Alm4/hRXbHu9PZmemHFFEIqQxjUhtrl/UX/rB\n",
       "s3RdshcbOoWlRzqvghGPwehbdmXXe6bbVm+fY0bHUmStT+z9ujHnjzk7KH/MVDTKnP+0eiod1h9O\n",
       "bdV7m9yx1bQqjj3rSjqunmTdFh9uWRtlWfuqZe1cy9rIdNKKSKVT91Qkkim6w5l5+PmMeOzb+TvW\n",
       "9QgtENvk/+NK4BTP+AMljikiEdCYRjtjF3U9l05rf1HEQ28HlhKKyEPAi7pQUEQ0phGpZveLdlr7\n",
       "S+DK/PdusHwQTP8CfDy08JGnAj8gXHn+L2C6Ze3UZsb9hNj7dWPOH3N2UP6YpTaIKs2XtBbOs6xd\n",
       "Czi/XDCc1f1/DexN18Vw0okw7Mn6njoSuM2ytsYzfq9lrROwAzBVLRARKYa6pyqEGVXAacClVNVs\n",
       "yw4PQ993Qytk8POLGPXnbnSo6ZY8fAWhBZIFtgceAY7zjFenEl5ESkpjGpJnRjdCQTgf6JO/Y4uP\n",
       "4bufXkvvuQ0tvX69Z/z7JYgoIilT0YiUmY1196fa5tz0IxSOHwJdABg4Cb61P3Ra29DTfkfYLGoD\n",
       "8HvPeKO7CbZl/lKIOX/M2UH506aBcPkEd5a4cy5hHOMmoIb5e8DfbgxdVgAzD3dmH/hhwdPOBI4F\n",
       "vgj81bJ2r2VtUImji0gZU0ujnTBjOPAT4Bts81p3Oq6BuftDxzXw7f1hwOSGnroAOMgzPr1kYUWk\n",
       "Tal7SopmRh/gG8nXaAB6fghjM4DBh6NX8ek73mH75/YoeNr7wBigGjgAOBoYC7wNfM8zPrt070BE\n",
       "WkpFI1Jp94uasTPwbeAMoO8md458eAVfPb4LHdZ3To5sADps8phZwDCWA//pGb+7zQO3srT//Vsi\n",
       "5uyg/GnTmIY0iztvu/MTYBDwHWDjqrkzju7JnX/rTE2uZtQpGBv1Au6yrD1oWRvWlnlFJH1qaUhe\n",
       "smLuScClwHAAdnoATvgqdFoT1rlaMegjarZ4mAFvPoz55fnHBWuBe4DngE6ELq2tgMcIs7GWlPDt\n",
       "iEgD1D0lrcqMzoSWx38Bw+i6GLqsgGVDwPON0zfpNedWvj9qDzqv/mYRp10DXAdc4Bnf0DbJRaQY\n",
       "KhqRKvd+UTOMMFh+UvK1/aaPeAoYu44d/vocX/rG9nT9uJgl2ccD3/KM17Zq2GYo93//xsScHZQ/\n",
       "bRrTkDbhjrvzanK9xzBgX+BmYHXBw7rwzjGHceWikdz61GJe/c4LLB3yLzZ0vJ/QUvkO8EbB408D\n",
       "fmNZ6547YFnbItnuVkTKnFoa0mQF03a/CezVwMOWE1oV1zHOZgK3AKcX3L8BeIew1MlAYB2huLwC\n",
       "TACe0SKKIm1D3VOSGjN2JRSPUwgf/vX5O51WXc+FPU/B/CtFnvpd4DWghjC591rP+PwWBxYRFY20\n",
       "czRXBfSL5vMnM6/GAF8AjiMsX7KpquoPOOa78xl1f3+2WDqYMGYCUMvmu0o/JnR33dZaLZCY//1j\n",
       "zg7KnzaNaUjq3Klx58nkuo8dgSOAvwIbP+BrOw/iwd+P5hcfD+GKpRsY/8Sr/OGZy/nl/D2p7t4f\n",
       "+DxwI7CsnpfoS+juetiyNqSt34+I1E8tDWlTZowAvkcYAO/XyENnAXcAtzHOPiC0WnonXxcSBuJz\n",
       "VgLXErqwVibn7QVMAh7XlF6Rxql7Sspe0n21L6E1cTSwZyMP/xdwG/CgO/OSmVaXEZZ539z/7w+S\n",
       "597qGX/HsmbA1sByz/iaFr4NkYqgohGpCugXbXZ+M7YBjiIUkCMILYX6zAWeB+7kgp5L6bLyZmDn\n",
       "Il/mTWBbwlXp84HjPeMvtUb+tMWcHZQ/bS357NTceEmFO/OAW4FbzdiCMID+DUIRKfy53A44GTiZ\n",
       "y1csoNPKN/js/y5kyLPrGPzCIjqt6QwsJoydfJHQqsj5dMHtgcA/LWsnAf9E43kizaKWhpQVM/oD\n",
       "XwFOBPYGujby8DXAHwljIU8zzqoIRecMQhFqaJHFnMcJV6fPaWlukZioe0oqUjIOshuhpfFNGr4O\n",
       "BGAh8CowD5jJTn+ZxJe/Xkvn1e8SisffgaH1PG8J8HNCC2VLQlfYg57xxa31PkTKjYpGpCqgX7Rk\n",
       "+ZMC8mlgMOEakFOB3TfztOXAk8Dj7HvNRD5/9sXAkcB6oDOzMOpfzH0D8CBwnmf8ndZ5B61LPzvp\n",
       "qoD8KhoxqoAfvNTyJ4sp7gt8HTiBxlshOW9gG+7FO9zLONuSmfyZEfRv5PHVwDWEpd3/7Rn/oMXB\n",
       "W4l+dtJVAflVNKT9MqMDodUxhDBbah/gc4TNpRryFr3fm8jxp42kz5waui16gS4rlgHHAvs18Jzn\n",
       "gLM94xNbMb5IyaloiNSRtER2IhSPI4HDgS6NPKUWeB14mv1/NZfPnf81OtTsXc/jHHiBcNFhB+Av\n",
       "hHWx5rVmfpG2pKIRqQpo4kaT34xehBlVJxBmWG2R7AfSwBM2OHvcOpvd7l7JoJc30GXlLoTdCOtT\n",
       "DfyJsGvhY57xda2bvp54Ef3b10f506WiEakK+MGLMr8ZPYAxcM3R8KMqQnfUHjR27caAN17nP87q\n",
       "z3Yvb7eZ068GpgLT2LjvyGTgd615RXqs//Y5yp8uFQ2RFjKjN3AgoelxMGHHwk8Wka2nQM8PYNUA\n",
       "2GbiFA68oj9bzhhQxEvMAs4GniF0hZ1AmAHWHfg1cE857GYo7YOKhkgrS7qzxhCuUv8SDa6e4LDN\n",
       "a/CpP8GnJjh9ZzX353EScAPwiGf8/WaeQ6QoKhqRqoAmbrvIb8ZA4DBC4agCjgeOob6WSLePoP9U\n",
       "6PsuVFU7fWYvZL9r+tJ5VecmRHseOL2xa0Tay799uaqA/Fp7SqStuDMfuLPg0K1mDAY+S7iSfAih\n",
       "iOzE6v4wuz/MPgjCirwDePFsOCQDOzwMXRdDl5WwZPhq3jvkBQa88RHbvnoctslyKZ8FXrGsnUaY\n",
       "5lvrGV9SgrcqsllqaYi0EjNGEbq09km+PkV9rRGrBS843OPDVex39SxGPNaPAZMHUrWhvgH5N4Bz\n",
       "POOPtUX2NFjWtiTss9KDMANtKvCQ9kNpe+qeEilDySytvdhYRHYjrH+1RYNP2mYinPwl6NPgGorP\n",
       "Ejaf+gh4AnjCM76+9VKXRrLPyVPAQXXuegL4mmd8YclDtSMqGpGqgH5R5W/ya2KEK9X3I7RKjqbu\n",
       "furdFsFRP4KRj0DHdevotLoK802vEZlFbi/DxcCjhGm9Uwn7hiwmXHw4gLAS8Gue8aWfyJI1a639\n",
       "1pvKxtolHEK2gbs/AE72jD9fykxNUQE/+yoaMaqAHzzlb3EGjLCp1H6ErqzBwAXAxoHzHvPgc+fX\n",
       "sPvtHbHk93Vj0SjWVOB+4G5gf8IuiNsAvwCu9ozXtOydFM+y1pkZvMvI/DIvjxAKxRls3JmxBjg3\n",
       "yVZ2H1Ll8LPTEioaIhXEjD2A24FdN7mj70wYMBm6Lq5l2JOz2OFvW9N1ac9WeMmJhOXhXyZcQ7IH\n",
       "G5eRryHsgPhSa314W9Z+QNjjHWApMMIzvsSydhRhwkHhXvLvAz2BdcDvgSs948taI0d7pqIhUmHM\n",
       "qCLMojqRsIji9p98UC1s+yoMfD1cdNhvJvSes5qeH6yjqmYRHarfp2N1H8KS8i2dKTkNuA9YmXw9\n",
       "5Bl/r8H8WRtIWDxyime8uuD4noTNr0JhePp/5vDkz+4ALnan1rI2BJhAGAOqz2LCplsTgec847Na\n",
       "+L7aJRWNSFVAE1f5S8SM7YFDCJtRjW103axNLaXTyvnses9aPnNjdwZOGoJXLaSq5hrMuwCX0PhC\n",
       "jg1ZA/w38NvCFkgyI+pnwFmE7rY1hOtOXiS0Ki4FujIL6De4lt9Mr6JmC4AL3bk8OUcX4FfA99jY\n",
       "XVUfJ6z3dRNhyvOxhKVbHgH+4hl/sfDBlrWOSa7PArd5xv/RjPcdzhXRz059VDQiVQE/eMqfAjN2\n",
       "hqu+Az9eAPQijIOMICx9UuxFhEuBVxjxyEscf3p/es4fRZjpBWF671RC11QfwgdyjwbOM4nQhVRD\n",
       "2NPkU0mmxs3oWM2zT3ROrmeB0C12hDtP5N9n1rYG+hN2ZTyCUIyGFvn+AH4HfM8zXmNZ2x24hbCF\n",
       "cM5dhE269k5e/6ee8fnFnDjWn50cFQ0RwYw+hKvVjyYMro+k8T3WC71H6PJ5LfnvRHcWAVjWugNf\n",
       "TM7ZkbBa8K71n2YTCwgzuDbl9g43vtGThbvV3TjrI+AU4DF3PvHBlLRADid8yB9IuEp/cx4mtD6+\n",
       "RGMLUgZvAmM848uLOG/UVDRE5BOScZEtCbOkci2R0cBnkuObM4dQRKYCs4F3gBcYZw5cBvwX9Xcf\n",
       "zQR+DDwFogK/AAAL1klEQVREaAWNAfYkjK28x7XT32LJDlcnj11I6GYqLC6vEbbbfR14yZ0F9b6/\n",
       "rO1L6O4aQ5h2fDNhj5NvEbqq6rOOsGjk4Q3c/0iSfS9Cq20BYVHJo5PXeZWwEVdRLZJypaIRqQpo\n",
       "4ip/SlqSPZnmuz2hy+eLwKEU3621jrC0yZts98JHfPqO1ez6xw/ptgTCB+x8YEZDK/aa0Q+YCE8N\n",
       "TcZkzgFeInxYd2vgNScRisI/gOfd2WS/krrXmyQXDl4OnFfnPP8AfuQZn2ZZO5JQXDokub9b3NsH\n",
       "YDFPcyMHc6VnfEUTnlc2VDQiFfOHFih/mlozuxmdCWMRowl/YY8mbJ9b7AD5esJf4FOA6YQr3gcl\n",
       "x58FnnLnIzNGAH8DdkoG8hcDQ91ZmQz0/wT4No1dMR+6mp4iFJFHgbfr68oCsKydCfw/Qsvlas/4\n",
       "mw2d1LJ2KXBRke+38DqZmcDTwN8J15psQxgHqiEU2Bc947OLPm+JqGiISKsyoxMwitCtNIzQMtk3\n",
       "OdYcuaVOCq9sP8OdW+u8bn9CV9CehG60fWh8uvCHhMHsd4F5hML1kjvVjTznE5LWyfWEFsdHhGtW\n",
       "PiZ0m3UmdGlNJ1zPMrgJp64ldLXdADzrGV9b8Jr9Ca2dwcCvPeMzmpK5JVQ0RKQkzNiOMGV1JLAD\n",
       "oZDs3MTTrAO+4c6fini9XoR+rCMJ3WkjG31CsJLwob8MWEUYj5lOGOie7E6DCyImg+3VDV3IaFnr\n",
       "TZimfDihgDbl+pdqwjhNbjzkKDa25j4GvugZf7oJ52s2FY1Ixdw9AsqfpnLKbsbWhG6t3IytVYSu\n",
       "mq0I4yWfYeOYyQzgG2BdmpPfjOGED+wjk3P3buIplhG6zJ5OvqYBK91p0q6JZjaWcbxA6Mo7ijCT\n",
       "qzOhtbOEMFYymLALZLHWA2d5xsc3JUtzqGhEqpx+8ZtD+dMTU/Zk4L0zYRbSx+54a+Q3oyOhWO1N\n",
       "GEvIfUgPbcbpFhEKyNSCr8nAB/VO/y12A6+s7ULo8joc2Kmeh0wkjP8UTj/+kWf82noe22pUNERE\n",
       "yBeoEcCOhGtUehFaPzsTFmrcpomnXEC42HEJsIJwIeM0QnfXdHdWF50tXKy4W5KpR3KeVwjF7q/J\n",
       "fYuBfT3jM5uYs0lUNERENiMpKDsQWiMHAwcQrjhv6Gr3YuSKSK6QTAP+DcxtaFZXvdmy1hMYTxgQ\n",
       "f64FeYp7PRWNOMXUxVAf5U9PzNmhvPKb0YHQRTSK0CIZBexCWO23gVWEn2Iza3/NIczqmkMY+F9G\n",
       "uOp+FqGFkurGWdojXESkmZLZVHOSr/wihskV9TsmXz0I118MB3aCtXsQuro6NHDaIYTFJetTbcZb\n",
       "hJlUrxNaJqsJxaUamFH3AsZyopaGiEgzJNeyJEWEnQjFZSfCNSYt6fLa2Z1pLU/YMHVPiYiUiaSY\n",
       "jCYMvPciXIuxFWFW147UtzfKpoa5814bRlTRSDtHc5VTv25zKH96Ys4O7Tu/GX0J4yV7Jl/bEwpL\n",
       "7utgdxa2UtQGMmhMQ0QkCu58TBgkfzLtLM2hloaISDvTks/OzW1KIiIikqeikSIzG5t2hpZQ/vTE\n",
       "nB2UP2YqGiIiUjSNaYiItDMa0xARkZIo26JhZseZ2c1m9kcza2gT+KjF3i+q/OmJOTsof8zKtmi4\n",
       "+wPufhbwn8DJaedpI3ukHaCFlD89MWcH5Y9WmxcNM/uDmS0ws8l1jh9lZm+b2Ttmdl4jp7gIuK5t\n",
       "U6amT9oBWkj50xNzdlD+aJWipXErYTvEPDPrQCgERxGWIP6qmY0ys1PN7Ndmtq0FvwD+7u6TSpBT\n",
       "REQ2o82XEXH3Z81saJ3D+wAz3P09ADP7I3Ccu18B3J4c+yFh391eZjbS3W9q66wpGJp2gBYamnaA\n",
       "FhqadoAWGJp2gBYamnaAFhqadoC0lGTKbVI0HnL33ZLvTwCOdPczk+9PAfZ19x808bzxzhcWEUlR\n",
       "bAsWtsqHva7REBEprbRmT31A2Ew9ZzAwN6UsIiJSpLSKxqvADmY21Mw6E6bUPphSFhERKVIpptze\n",
       "DfwL2NHM3jez0929Bvg+YT/efwP3uPvUJp632Cm7qTOzwWb2pJm9ZWZTkkF+zKyfmT1mZtPN7FEz\n",
       "K+tpfGbWwcxeN7OHku+jyW9mfczsXjObamb/NrN9I8t/QfLzM9nM7jKzLuWcv76p9o3lTd7fO8nv\n",
       "9BHppM5nqS/7L5OfnTfM7H4z611wX9lkT/LUe5lDct9/m1mtmfUrONa0/O4e3RdhM/cZhBkMnYBJ\n",
       "wKi0czWSdyCwR3K7BzANGAVcCZybHD8PuCLtrJt5Hz8G7gQeTL6PJj/wf8AZye2OQO9Y8ic/5+8C\n",
       "XZLv7wG+Wc75gTGEXekmFxyrNy9h2v2k5Hd5aPK7XVVm2Q/PZQKuKNfsDeVPjg8GHgFmAf2am79s\n",
       "rwjfjPyUXXdfD/wROC7lTA1y9/meXGvi7iuBqcAg4FjChxnJf49PJ+Hmmdl2wNHALUBuAkIU+ZO/\n",
       "Cse4+x8A3L3G3ZcRSX5gObAe6GZmHYFuwIeUcX53fxb4uM7hhvIeB9zt7us9TMOfQfgdT0V92d39\n",
       "MXevTb59CdguuV1W2aHBf3uAq4Bz6xxrcv5Yi8Yg4P2C7+cmx8peMv14T8IP3gB3X5DctQAYkFKs\n",
       "YvwaOAeoLTgWS/5hwEdmdquZvWZmvzOz7kSS392XAL8C5hCKxVJ3f4xI8hdoKO+2bDoRptx/n88A\n",
       "Hk5uR5HdzI4D5rr7m3XuanL+WItGlNdnmFkP4D7gR+6+ovA+D23FsnxfZnYMsNDdX2djK2MT5Zyf\n",
       "0B21F3CDu+8FrALOL3xAOec3sxHA2YTug22BHsm1TXnlnL8+ReQty/diZv8DVLv7XY08rKyym1k3\n",
       "4EIgU3i4kac0mj/WohHdlF0z60QoGLe7+1+SwwvMbGBy/zbAwrTybcYBwLFmNgu4GzjUzG4nnvxz\n",
       "CX9lvZJ8fy+hiMyPJP/ewL/cfbGHSST3A/sTT/6chn5e6v4+b5ccKytmdhqhi/brBYdjyD6C8AfH\n",
       "G8nv8HbARDMbQDPyx1o0opqya2YG/B74t7tfXXDXg4QBTZL//qXuc8uBu1/o7oPdfRjwFeCf7n4q\n",
       "8eSfD7xvZjsmhz4HvAU8RAT5gbeB/cysa/Kz9DnCrMNY8uc09PPyIPAVM+tsZsOAHYCXU8jXIDM7\n",
       "itA9e5y7ry24q+yzu/tkdx/g7sOS3+G5wF5JV2HT86c5yt/CGQKfJ8xCmgFckHaezWQ9kDAWMAl4\n",
       "Pfk6CugHPA5MBx4F+qSdtYj3cjAbZ09Fkx/YHXgFeIPwl3rvyPKfSyh0kwmDyJ3KOT+hRfohUE0Y\n",
       "fzy9sbyE7pMZhAJ5ZJllPwN4B5hd8Pt7Qzlmr5N/Xe7fvs7975LMnmpO/qi3exURkdKKtXtKRERS\n",
       "oKIhIiJFU9EQEZGiqWiIiEjRVDRERKRoKhoiIlI0FQ2RlJjZ2Nwy8yKxUNEQEZGiqWiIbIaZnWJm\n",
       "LyUbUP022YxqpZldlWyq9biZbZU8dg8ze7Fgs54+yfGRyeMmmdlEMxtOWBiuh5lNSDb4uSPN9ylS\n",
       "DBUNkUaY2SjgJOAAd98T2EBYsK4b8Iq77wo8zcYVRG8DznH33QlLfuSO3wn8xt33ICw2OI+w0uie\n",
       "wI8Im+EMN7PPluSNiTRTx7QDiJS5w4DRwKthrUC2IKzOWkvYQQ/gDuB+M+sF9PawCQ6ENaImJEvi\n",
       "b+vuDwC4ezVAcr6X3f3D5PtJhNVIn2/7tyXSPCoaIpv3f+5+YeEBM7u48Fvq34OgsT0LctYV3N6A\n",
       "fielzKl7SqRxTwAnmFl/ADPrZ2bbE353Tkwe8zXgWXdfDnxsZgcmx08FnvKwxe/cZPc0zKyLmXUt\n",
       "6bsQaSX6q0akEe4+1cwuAh41syrCctnfJ+z+t09y3wLCni4Q9on4bbJb2kzCkuAQCshNZvbT5Bwn\n",
       "EVondVsoWnZaypqWRhdpBjNb4e49084hUmrqnhJpHv21Je2SWhoiIlI0tTRERKRoKhoiIlI0FQ0R\n",
       "ESmaioaIiBRNRUNERIqmoiEiIkX7/ydI1rfBl/LTAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b9979afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = np.array([i[\"train_loss\"] for i in net3.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net3.train_history_])\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(1e-2, 3e-2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input             \t(None, 1, 65, 65)   \tproduces    4225 outputs\n",
      "  conv1             \t(None, 32, 63, 63)  \tproduces  127008 outputs\n",
      "  pool1             \t(None, 32, 32, 32)  \tproduces   32768 outputs\n",
      "  dropout1          \t(None, 32, 32, 32)  \tproduces   32768 outputs\n",
      "  conv2             \t(None, 64, 31, 31)  \tproduces   61504 outputs\n",
      "  pool2             \t(None, 64, 16, 16)  \tproduces   16384 outputs\n",
      "  dropout2          \t(None, 64, 16, 16)  \tproduces   16384 outputs\n",
      "  conv3             \t(None, 128, 15, 15) \tproduces   28800 outputs\n",
      "  pool3             \t(None, 128, 8, 8)   \tproduces    8192 outputs\n",
      "  dropout3          \t(None, 128, 8, 8)   \tproduces    8192 outputs\n",
      "  hidden4           \t(None, 500)         \tproduces     500 outputs\n",
      "  dropout4          \t(None, 500)         \tproduces     500 outputs\n",
      "  hidden5           \t(None, 500)         \tproduces     500 outputs\n",
      "  dropout5          \t(None, 500)         \tproduces     500 outputs\n",
      "  hidden6           \t(None, 500)         \tproduces     500 outputs\n",
      "  output            \t(None, 37)          \tproduces      37 outputs\n",
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  0.036632\u001b[0m  |  \u001b[32m  0.026984\u001b[0m  |     1.357581  |             |  29.0s\n",
      "     2  |  \u001b[94m  0.027260\u001b[0m  |  \u001b[32m  0.026700\u001b[0m  |     1.020961  |             |  29.0s\n",
      "     3  |  \u001b[94m  0.027060\u001b[0m  |  \u001b[32m  0.026623\u001b[0m  |     1.016412  |             |  29.0s\n",
      "     4  |  \u001b[94m  0.027000\u001b[0m  |  \u001b[32m  0.026599\u001b[0m  |     1.015058  |             |  29.0s\n",
      "     5  |  \u001b[94m  0.026963\u001b[0m  |  \u001b[32m  0.026587\u001b[0m  |     1.014135  |             |  29.0s\n",
      "     6  |  \u001b[94m  0.026939\u001b[0m  |  \u001b[32m  0.026576\u001b[0m  |     1.013674  |             |  29.0s\n",
      "     7  |  \u001b[94m  0.026919\u001b[0m  |  \u001b[32m  0.026568\u001b[0m  |     1.013212  |             |  29.0s\n",
      "     8  |  \u001b[94m  0.026902\u001b[0m  |  \u001b[32m  0.026559\u001b[0m  |     1.012927  |             |  29.0s\n",
      "     9  |  \u001b[94m  0.026886\u001b[0m  |  \u001b[32m  0.026546\u001b[0m  |     1.012793  |             |  29.0s\n",
      "    10  |  \u001b[94m  0.026873\u001b[0m  |  \u001b[32m  0.026535\u001b[0m  |     1.012721  |             |  29.0s\n",
      "    11  |  \u001b[94m  0.026857\u001b[0m  |  \u001b[32m  0.026521\u001b[0m  |     1.012692  |             |  29.0s\n",
      "    12  |  \u001b[94m  0.026839\u001b[0m  |  \u001b[32m  0.026506\u001b[0m  |     1.012563  |             |  29.0s\n",
      "    13  |  \u001b[94m  0.026822\u001b[0m  |  \u001b[32m  0.026491\u001b[0m  |     1.012480  |             |  29.0s\n",
      "    14  |  \u001b[94m  0.026804\u001b[0m  |  \u001b[32m  0.026474\u001b[0m  |     1.012436  |             |  29.0s\n",
      "    15  |  \u001b[94m  0.026784\u001b[0m  |  \u001b[32m  0.026454\u001b[0m  |     1.012452  |             |  29.0s\n",
      "    16  |  \u001b[94m  0.026764\u001b[0m  |  \u001b[32m  0.026431\u001b[0m  |     1.012610  |             |  29.0s\n",
      "    17  |  \u001b[94m  0.026736\u001b[0m  |  \u001b[32m  0.026398\u001b[0m  |     1.012806  |             |  29.0s\n",
      "    18  |  \u001b[94m  0.026697\u001b[0m  |  \u001b[32m  0.026359\u001b[0m  |     1.012833  |             |  29.0s\n",
      "    19  |  \u001b[94m  0.026662\u001b[0m  |  \u001b[32m  0.026315\u001b[0m  |     1.013173  |             |  29.0s\n",
      "    20  |  \u001b[94m  0.026612\u001b[0m  |  \u001b[32m  0.026254\u001b[0m  |     1.013636  |             |  29.0s\n",
      "    21  |  \u001b[94m  0.026564\u001b[0m  |  \u001b[32m  0.026185\u001b[0m  |     1.014500  |             |  29.0s\n",
      "    22  |  \u001b[94m  0.026492\u001b[0m  |  \u001b[32m  0.026091\u001b[0m  |     1.015389  |             |  29.0s\n",
      "    23  |  \u001b[94m  0.026414\u001b[0m  |  \u001b[32m  0.026000\u001b[0m  |     1.015936  |             |  29.0s\n",
      "    24  |  \u001b[94m  0.026334\u001b[0m  |  \u001b[32m  0.025894\u001b[0m  |     1.016993  |             |  29.0s\n",
      "    25  |  \u001b[94m  0.026245\u001b[0m  |  \u001b[32m  0.025788\u001b[0m  |     1.017699  |             |  29.0s\n",
      "    26  |  \u001b[94m  0.026155\u001b[0m  |  \u001b[32m  0.025665\u001b[0m  |     1.019056  |             |  29.0s\n",
      "    27  |  \u001b[94m  0.026042\u001b[0m  |  \u001b[32m  0.025531\u001b[0m  |     1.020018  |             |  29.0s\n",
      "    28  |  \u001b[94m  0.025930\u001b[0m  |  \u001b[32m  0.025402\u001b[0m  |     1.020807  |             |  29.0s\n",
      "    29  |  \u001b[94m  0.025816\u001b[0m  |  \u001b[32m  0.025268\u001b[0m  |     1.021723  |             |  29.0s\n",
      "    30  |  \u001b[94m  0.025731\u001b[0m  |  \u001b[32m  0.025152\u001b[0m  |     1.022997  |             |  29.0s\n",
      "    31  |  \u001b[94m  0.025610\u001b[0m  |  \u001b[32m  0.025024\u001b[0m  |     1.023404  |             |  29.0s\n",
      "    32  |  \u001b[94m  0.025504\u001b[0m  |  \u001b[32m  0.024922\u001b[0m  |     1.023368  |             |  29.1s\n",
      "    33  |  \u001b[94m  0.025403\u001b[0m  |  \u001b[32m  0.024798\u001b[0m  |     1.024370  |             |  29.0s\n",
      "    34  |  \u001b[94m  0.025300\u001b[0m  |  \u001b[32m  0.024719\u001b[0m  |     1.023528  |             |  29.1s\n",
      "    35  |  \u001b[94m  0.025230\u001b[0m  |  \u001b[32m  0.024611\u001b[0m  |     1.025135  |             |  29.1s\n",
      "    36  |  \u001b[94m  0.025132\u001b[0m  |  \u001b[32m  0.024528\u001b[0m  |     1.024635  |             |  29.0s\n",
      "    37  |  \u001b[94m  0.025045\u001b[0m  |  \u001b[32m  0.024478\u001b[0m  |     1.023171  |             |  29.0s\n",
      "    38  |  \u001b[94m  0.024950\u001b[0m  |  \u001b[32m  0.024400\u001b[0m  |     1.022547  |             |  29.0s\n",
      "    39  |  \u001b[94m  0.024880\u001b[0m  |  \u001b[32m  0.024317\u001b[0m  |     1.023129  |             |  29.0s\n",
      "    40  |  \u001b[94m  0.024782\u001b[0m  |    0.024466  |     1.012916  |             |  29.0s\n",
      "    41  |  \u001b[94m  0.024705\u001b[0m  |  \u001b[32m  0.024242\u001b[0m  |     1.019073  |             |  29.0s\n",
      "    42  |  \u001b[94m  0.024607\u001b[0m  |    0.024291  |     1.013004  |             |  29.0s\n",
      "    43  |  \u001b[94m  0.024512\u001b[0m  |    0.024311  |     1.008240  |             |  29.0s\n",
      "    44  |  \u001b[94m  0.024419\u001b[0m  |    0.024409  |     1.000400  |             |  29.0s\n",
      "    45  |  \u001b[94m  0.024319\u001b[0m  |  \u001b[32m  0.024064\u001b[0m  |     1.010604  |             |  29.0s\n",
      "    46  |  \u001b[94m  0.024210\u001b[0m  |  \u001b[32m  0.023894\u001b[0m  |     1.013216  |             |  29.0s\n",
      "    47  |  \u001b[94m  0.024098\u001b[0m  |    0.023944  |     1.006410  |             |  29.0s\n",
      "    48  |  \u001b[94m  0.023950\u001b[0m  |  \u001b[32m  0.023855\u001b[0m  |     1.003970  |             |  29.0s\n",
      "    49  |  \u001b[94m  0.023852\u001b[0m  |    0.023960  |     0.995515  |             |  29.0s\n",
      "    50  |  \u001b[94m  0.023730\u001b[0m  |    0.023884  |     0.993554  |             |  29.0s\n",
      "    51  |  \u001b[94m  0.023582\u001b[0m  |  \u001b[32m  0.023715\u001b[0m  |     0.994426  |             |  29.0s\n",
      "    52  |  \u001b[94m  0.023474\u001b[0m  |    0.024070  |     0.975257  |             |  29.0s\n",
      "    53  |  \u001b[94m  0.023362\u001b[0m  |    0.023825  |     0.980580  |             |  29.0s\n",
      "    54  |  \u001b[94m  0.023229\u001b[0m  |    0.023736  |     0.978637  |             |  29.0s\n",
      "    55  |  \u001b[94m  0.023123\u001b[0m  |  \u001b[32m  0.023316\u001b[0m  |     0.991715  |             |  29.0s\n",
      "    56  |  \u001b[94m  0.023027\u001b[0m  |  \u001b[32m  0.023272\u001b[0m  |     0.989455  |             |  29.0s\n",
      "    57  |  \u001b[94m  0.022879\u001b[0m  |  \u001b[32m  0.023154\u001b[0m  |     0.988117  |             |  29.0s\n",
      "    58  |  \u001b[94m  0.022811\u001b[0m  |  \u001b[32m  0.023144\u001b[0m  |     0.985608  |             |  29.1s\n",
      "    59  |  \u001b[94m  0.022675\u001b[0m  |    0.023194  |     0.977624  |             |  29.1s\n",
      "    60  |  \u001b[94m  0.022557\u001b[0m  |  \u001b[32m  0.022804\u001b[0m  |     0.989158  |             |  29.1s\n",
      "    61  |  \u001b[94m  0.022457\u001b[0m  |    0.022871  |     0.981894  |             |  29.0s\n",
      "    62  |  \u001b[94m  0.022350\u001b[0m  |  \u001b[32m  0.022741\u001b[0m  |     0.982807  |             |  29.1s\n",
      "    63  |  \u001b[94m  0.022249\u001b[0m  |    0.023049  |     0.965296  |             |  29.1s\n",
      "    64  |  \u001b[94m  0.022180\u001b[0m  |    0.022748  |     0.975037  |             |  29.0s\n",
      "    65  |  \u001b[94m  0.022071\u001b[0m  |  \u001b[32m  0.022309\u001b[0m  |     0.989341  |             |  29.0s\n",
      "    66  |  \u001b[94m  0.022019\u001b[0m  |  \u001b[32m  0.022078\u001b[0m  |     0.997330  |             |  29.0s\n",
      "    67  |  \u001b[94m  0.021933\u001b[0m  |    0.022434  |     0.977655  |             |  29.0s\n",
      "    68  |  \u001b[94m  0.021822\u001b[0m  |    0.022358  |     0.976040  |             |  29.0s\n",
      "    69  |  \u001b[94m  0.021764\u001b[0m  |    0.022635  |     0.961552  |             |  29.0s\n",
      "    70  |  \u001b[94m  0.021681\u001b[0m  |    0.022461  |     0.965306  |             |  29.0s\n",
      "    71  |  \u001b[94m  0.021605\u001b[0m  |    0.022244  |     0.971264  |             |  29.0s\n",
      "    72  |  \u001b[94m  0.021571\u001b[0m  |    0.022486  |     0.959295  |             |  29.0s\n",
      "    73  |  \u001b[94m  0.021476\u001b[0m  |    0.022249  |     0.965251  |             |  29.0s\n",
      "    74  |  \u001b[94m  0.021426\u001b[0m  |    0.022093  |     0.969827  |             |  29.0s\n",
      "    75  |  \u001b[94m  0.021382\u001b[0m  |  \u001b[32m  0.021928\u001b[0m  |     0.975077  |             |  29.0s\n",
      "    76  |  \u001b[94m  0.021335\u001b[0m  |    0.022668  |     0.941184  |             |  29.0s\n",
      "    77  |  \u001b[94m  0.021252\u001b[0m  |    0.021996  |     0.966166  |             |  29.0s\n",
      "    78  |  \u001b[94m  0.021218\u001b[0m  |    0.022412  |     0.946726  |             |  29.0s\n",
      "    79  |  \u001b[94m  0.021171\u001b[0m  |    0.022549  |     0.938883  |             |  29.0s\n",
      "    80  |  \u001b[94m  0.021094\u001b[0m  |    0.022299  |     0.945943  |             |  29.0s\n",
      "    81  |  \u001b[94m  0.021087\u001b[0m  |    0.022264  |     0.947127  |             |  29.0s\n",
      "    82  |  \u001b[94m  0.021026\u001b[0m  |    0.021994  |     0.956029  |             |  29.0s\n",
      "    83  |  \u001b[94m  0.021016\u001b[0m  |    0.023308  |     0.901661  |             |  29.0s\n",
      "    84  |  \u001b[94m  0.020918\u001b[0m  |    0.022309  |     0.937670  |             |  29.0s\n",
      "    85  |  \u001b[94m  0.020903\u001b[0m  |    0.022923  |     0.911889  |             |  29.0s\n",
      "    86  |  \u001b[94m  0.020894\u001b[0m  |    0.022749  |     0.918460  |             |  29.0s\n",
      "    87  |  \u001b[94m  0.020847\u001b[0m  |    0.022886  |     0.910915  |             |  29.0s\n",
      "    88  |  \u001b[94m  0.020847\u001b[0m  |    0.022779  |     0.915188  |             |  29.0s\n",
      "    89  |  \u001b[94m  0.020758\u001b[0m  |    0.023128  |     0.897512  |             |  29.0s\n",
      "    90  |    0.020765  |    0.023045  |     0.901043  |             |  29.0s\n",
      "    91  |  \u001b[94m  0.020733\u001b[0m  |    0.023663  |     0.876156  |             |  29.0s\n",
      "    92  |  \u001b[94m  0.020702\u001b[0m  |    0.023189  |     0.892746  |             |  29.0s\n",
      "    93  |  \u001b[94m  0.020687\u001b[0m  |    0.023790  |     0.869590  |             |  29.0s\n",
      "    94  |  \u001b[94m  0.020625\u001b[0m  |    0.023786  |     0.867117  |             |  29.0s\n",
      "    95  |  \u001b[94m  0.020619\u001b[0m  |    0.023922  |     0.861925  |             |  29.0s\n",
      "    96  |  \u001b[94m  0.020590\u001b[0m  |    0.023517  |     0.875520  |             |  29.0s\n",
      "    97  |  \u001b[94m  0.020565\u001b[0m  |    0.023799  |     0.864145  |             |  29.0s\n",
      "    98  |  \u001b[94m  0.020496\u001b[0m  |    0.023434  |     0.874647  |             |  29.0s\n",
      "    99  |    0.020517  |    0.023441  |     0.875273  |             |  29.1s\n",
      "   100  |  \u001b[94m  0.020488\u001b[0m  |    0.023488  |     0.872284  |             |  29.0s\n",
      "   101  |  \u001b[94m  0.020455\u001b[0m  |    0.022865  |     0.894562  |             |  29.0s\n",
      "   102  |  \u001b[94m  0.020443\u001b[0m  |    0.024064  |     0.849519  |             |  29.0s\n",
      "   103  |  \u001b[94m  0.020417\u001b[0m  |    0.022888  |     0.892029  |             |  29.0s\n",
      "   104  |  \u001b[94m  0.020395\u001b[0m  |    0.023457  |     0.869490  |             |  29.0s\n",
      "   105  |  \u001b[94m  0.020372\u001b[0m  |    0.023715  |     0.859026  |             |  29.0s\n",
      "   106  |  \u001b[94m  0.020324\u001b[0m  |    0.023671  |     0.858637  |             |  29.0s\n",
      "   107  |    0.020327  |    0.024037  |     0.845675  |             |  29.0s\n",
      "   108  |  \u001b[94m  0.020277\u001b[0m  |    0.024005  |     0.844715  |             |  29.0s\n",
      "   109  |  \u001b[94m  0.020263\u001b[0m  |    0.024042  |     0.842845  |             |  29.0s\n",
      "   110  |  \u001b[94m  0.020247\u001b[0m  |    0.024413  |     0.829380  |             |  29.1s\n",
      "   111  |    0.020251  |    0.023651  |     0.856222  |             |  29.1s\n",
      "   112  |  \u001b[94m  0.020224\u001b[0m  |    0.024011  |     0.842282  |             |  29.1s\n",
      "   113  |  \u001b[94m  0.020198\u001b[0m  |    0.025244  |     0.800109  |             |  29.1s\n",
      "   114  |  \u001b[94m  0.020192\u001b[0m  |    0.024572  |     0.821728  |             |  29.0s\n",
      "   115  |  \u001b[94m  0.020157\u001b[0m  |    0.023834  |     0.845727  |             |  29.0s\n",
      "   116  |  \u001b[94m  0.020140\u001b[0m  |    0.024735  |     0.814219  |             |  29.1s\n",
      "   117  |  \u001b[94m  0.020118\u001b[0m  |    0.024982  |     0.805309  |             |  29.1s\n",
      "   118  |  \u001b[94m  0.020103\u001b[0m  |    0.024013  |     0.837203  |             |  29.0s\n",
      "   119  |  \u001b[94m  0.020080\u001b[0m  |    0.023296  |     0.861935  |             |  29.0s\n",
      "   120  |  \u001b[94m  0.020052\u001b[0m  |    0.023656  |     0.847631  |             |  29.1s\n",
      "   121  |    0.020070  |    0.025019  |     0.802175  |             |  29.1s\n",
      "   122  |  \u001b[94m  0.020035\u001b[0m  |    0.023627  |     0.847983  |             |  29.1s\n",
      "   123  |  \u001b[94m  0.019995\u001b[0m  |    0.024591  |     0.813113  |             |  29.1s\n",
      "   124  |    0.020020  |    0.024890  |     0.804365  |             |  29.1s\n",
      "   125  |  \u001b[94m  0.019983\u001b[0m  |    0.024517  |     0.815040  |             |  29.1s\n",
      "   126  |  \u001b[94m  0.019960\u001b[0m  |    0.025181  |     0.792655  |             |  29.1s\n",
      "   127  |  \u001b[94m  0.019932\u001b[0m  |    0.024156  |     0.825132  |             |  29.1s\n",
      "   128  |  \u001b[94m  0.019901\u001b[0m  |    0.023593  |     0.843514  |             |  29.1s\n",
      "   129  |  \u001b[94m  0.019891\u001b[0m  |    0.024128  |     0.824378  |             |  29.1s\n",
      "   130  |    0.019916  |    0.024245  |     0.821426  |             |  29.1s\n",
      "   131  |  \u001b[94m  0.019852\u001b[0m  |    0.024249  |     0.818660  |             |  29.1s\n",
      "   132  |    0.019875  |    0.023847  |     0.833438  |             |  29.1s\n",
      "   133  |  \u001b[94m  0.019821\u001b[0m  |    0.024512  |     0.808614  |             |  29.1s\n",
      "   134  |    0.019829  |    0.023441  |     0.845918  |             |  29.1s\n",
      "   135  |  \u001b[94m  0.019784\u001b[0m  |    0.023640  |     0.836889  |             |  29.1s\n",
      "   136  |  \u001b[94m  0.019775\u001b[0m  |    0.024344  |     0.812318  |             |  29.1s\n",
      "   137  |    0.019800  |    0.023964  |     0.826205  |             |  29.1s\n",
      "   138  |    0.019777  |    0.023525  |     0.840673  |             |  29.1s\n",
      "   139  |  \u001b[94m  0.019719\u001b[0m  |    0.024586  |     0.802032  |             |  29.1s\n",
      "   140  |  \u001b[94m  0.019711\u001b[0m  |    0.024251  |     0.812795  |             |  29.1s\n",
      "   141  |  \u001b[94m  0.019694\u001b[0m  |    0.023948  |     0.822369  |             |  29.1s\n",
      "   142  |  \u001b[94m  0.019681\u001b[0m  |    0.024878  |     0.791096  |             |  29.0s\n",
      "   143  |  \u001b[94m  0.019671\u001b[0m  |    0.024313  |     0.809085  |             |  29.1s\n",
      "   144  |  \u001b[94m  0.019606\u001b[0m  |    0.024485  |     0.800744  |             |  29.1s\n",
      "   145  |    0.019646  |    0.024201  |     0.811788  |             |  29.1s\n",
      "   146  |    0.019646  |    0.024024  |     0.817753  |             |  29.1s\n",
      "   147  |  \u001b[94m  0.019592\u001b[0m  |    0.023210  |     0.844102  |             |  29.1s\n",
      "   148  |    0.019602  |    0.023761  |     0.824986  |             |  29.1s\n",
      "   149  |    0.019606  |    0.023832  |     0.822684  |             |  29.1s\n",
      "   150  |    0.019616  |    0.023024  |     0.851997  |             |  29.1s\n",
      "   151  |  \u001b[94m  0.019543\u001b[0m  |    0.023348  |     0.837034  |             |  29.1s\n",
      "   152  |  \u001b[94m  0.019518\u001b[0m  |    0.024231  |     0.805503  |             |  29.1s\n",
      "   153  |  \u001b[94m  0.019500\u001b[0m  |    0.023531  |     0.828700  |             |  29.1s\n",
      "   154  |    0.019502  |    0.022970  |     0.849008  |             |  29.1s\n",
      "   155  |    0.019508  |    0.022890  |     0.852220  |             |  29.1s\n",
      "   156  |  \u001b[94m  0.019460\u001b[0m  |    0.022797  |     0.853607  |             |  29.1s\n",
      "   157  |  \u001b[94m  0.019442\u001b[0m  |    0.022879  |     0.849785  |             |  29.1s\n",
      "   158  |    0.019447  |    0.022561  |     0.861977  |             |  29.1s\n",
      "   159  |    0.019478  |    0.022894  |     0.850810  |             |  29.1s\n",
      "   160  |  \u001b[94m  0.019412\u001b[0m  |    0.023177  |     0.837562  |             |  29.1s\n",
      "   161  |  \u001b[94m  0.019399\u001b[0m  |    0.023028  |     0.842416  |             |  29.1s\n",
      "   162  |  \u001b[94m  0.019380\u001b[0m  |    0.022583  |     0.858176  |             |  29.1s\n",
      "   163  |  \u001b[94m  0.019324\u001b[0m  |    0.023047  |     0.838462  |             |  29.1s\n",
      "   164  |    0.019327  |    0.022855  |     0.845620  |             |  29.1s\n",
      "   165  |    0.019330  |    0.023122  |     0.835980  |             |  29.1s\n",
      "   166  |  \u001b[94m  0.019314\u001b[0m  |    0.023037  |     0.838425  |             |  29.1s\n",
      "   167  |  \u001b[94m  0.019269\u001b[0m  |    0.023149  |     0.832386  |             |  29.1s\n",
      "   168  |    0.019317  |    0.022235  |     0.868785  |             |  29.0s\n",
      "   169  |  \u001b[94m  0.019227\u001b[0m  |    0.022977  |     0.836803  |             |  29.0s\n",
      "   170  |    0.019243  |    0.023056  |     0.834603  |             |  29.0s\n",
      "   171  |    0.019245  |    0.022457  |     0.856981  |             |  29.1s\n",
      "   172  |    0.019241  |    0.022843  |     0.842326  |             |  29.0s\n",
      "   173  |  \u001b[94m  0.019196\u001b[0m  |    0.022900  |     0.838231  |             |  29.0s\n",
      "   174  |    0.019227  |    0.022612  |     0.850317  |             |  29.0s\n",
      "   175  |  \u001b[94m  0.019178\u001b[0m  |    0.022644  |     0.846954  |             |  29.1s\n",
      "   176  |  \u001b[94m  0.019160\u001b[0m  |    0.023091  |     0.829748  |             |  29.1s\n",
      "   177  |    0.019161  |    0.022591  |     0.848145  |             |  29.0s\n",
      "   178  |  \u001b[94m  0.019129\u001b[0m  |    0.022352  |     0.855779  |             |  29.0s\n",
      "   179  |  \u001b[94m  0.019091\u001b[0m  |    0.022786  |     0.837858  |             |  29.0s\n",
      "   180  |    0.019114  |    0.022825  |     0.837406  |             |  29.0s\n",
      "   181  |    0.019095  |    0.022553  |     0.846693  |             |  29.0s\n",
      "   182  |    0.019098  |    0.023005  |     0.830185  |             |  29.0s\n",
      "   183  |  \u001b[94m  0.019078\u001b[0m  |    0.022783  |     0.837345  |             |  29.0s\n",
      "   184  |  \u001b[94m  0.019028\u001b[0m  |    0.023113  |     0.823256  |             |  29.0s\n",
      "   185  |    0.019030  |    0.023149  |     0.822064  |             |  29.0s\n",
      "   186  |  \u001b[94m  0.019012\u001b[0m  |    0.023186  |     0.819991  |             |  29.0s\n",
      "   187  |    0.019030  |    0.022811  |     0.834235  |             |  29.0s\n",
      "   188  |  \u001b[94m  0.019008\u001b[0m  |    0.023048  |     0.824703  |             |  29.0s\n",
      "   189  |  \u001b[94m  0.018964\u001b[0m  |    0.023150  |     0.819149  |             |  29.0s\n",
      "   190  |    0.019000  |    0.022962  |     0.827468  |             |  29.0s\n",
      "   191  |    0.018965  |    0.022432  |     0.845435  |             |  29.0s\n",
      "   192  |    0.018968  |    0.022322  |     0.849707  |             |  29.0s\n",
      "   193  |  \u001b[94m  0.018953\u001b[0m  |    0.021983  |     0.862177  |             |  29.0s\n",
      "   194  |  \u001b[94m  0.018939\u001b[0m  |  \u001b[32m  0.021833\u001b[0m  |     0.867446  |             |  29.0s\n",
      "   195  |  \u001b[94m  0.018927\u001b[0m  |    0.022165  |     0.853908  |             |  29.0s\n",
      "   196  |  \u001b[94m  0.018918\u001b[0m  |    0.022424  |     0.843644  |             |  29.0s\n",
      "   197  |  \u001b[94m  0.018867\u001b[0m  |    0.022516  |     0.837925  |             |  29.0s\n",
      "   198  |  \u001b[94m  0.018810\u001b[0m  |    0.022451  |     0.837816  |             |  29.0s\n",
      "   199  |  \u001b[94m  0.018808\u001b[0m  |    0.022357  |     0.841239  |             |  29.0s\n",
      "   200  |    0.018843  |  \u001b[32m  0.021726\u001b[0m  |     0.867297  |             |  29.0s\n"
     ]
    }
   ],
   "source": [
    "net4 = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('dropout1', layers.DropoutLayer),  # !\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('dropout2', layers.DropoutLayer),  # !\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('dropout3', layers.DropoutLayer),  # !\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('dropout4', layers.DropoutLayer),  # !\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        \n",
    "        ('dropout5', layers.DropoutLayer),  # !\n",
    "        ('hidden6', layers.DenseLayer),\n",
    "        \n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 65, 65),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_ds=(2, 2),\n",
    "    dropout1_p=0.1,  # !\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_ds=(2, 2),\n",
    "    dropout2_p=0.2,  # !\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_ds=(2, 2),\n",
    "    dropout3_p=0.3,  # !\n",
    "    hidden4_num_units=500, \n",
    "    dropout4_p=0.5,  # !\n",
    "    hidden5_num_units=500,\n",
    "    \n",
    "    dropout5_p=0.5,  # !\n",
    "    hidden6_num_units=500,\n",
    "    output_num_units=37, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    batch_iterator_train=FlipBatchIterator(batch_size=512),\n",
    "    batch_iterator_test=FlipBatchIterator(batch_size=512),\n",
    "    regression=True,\n",
    "    max_epochs=200,\n",
    "    verbose=1,\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "net4.fit(X, y)\n",
    "with open(\"pickles/net4.pickle\", \"wb\") as out:\n",
    "    pickle.dump(net4, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHFXV//HPSSBhCUmAQNgN+yJoFEVkE0RlEUFBwQ0B\n",
       "kQd/oD6oj6IIVkoEERcUAUEBWQVEQEAFERGRLWwJ+05QtiyEBBJC1jm/P071TE1P90zPTE0vM9/3\n",
       "69WvTFdXd9+56anT9567mLsjIiJSi2GNLoCIiLQOBQ0REamZgoaIiNRMQUNERGqmoCEiIjVT0BAR\n",
       "kZot1+gC9IeZabywiEgfuLv15XktHTSCAzzizjaNLkmrM7NJ7j6p0eUYLFSfxVFdFqs/X7gHS/fU\n",
       "yEYXYJCY0OgCDDITGl2AQWRCowsgQUFDRERqpqAheRc0ugCDzAWNLsAgckGjCyDBWnntqeiXc4C5\n",
       "7qza6PKIiLQCM/MhnAgH1NIohJnt6u63Nrocg4Xqszjd1aVGUXavr8GhmkETNMwwd/ThERmCir4w\n",
       "DhYDEVAHS/cUwAh3ljSyPCJSf/3pahnsqtVNf+pssCTCQV1UIiIDTkFD2pnZro0uw2Ci+iyO6rJ5\n",
       "KGiIiDQxM/u1mR3f6HKUDKacxkbuTGtkeUSk/po9p2FmzwNfdPdbGvDeyml0Qy0NEWlGDlS8QJtZ\n",
       "y41gVdCQduo3LpbqszitWpdmdjGwAXC9mc0zs2+ZWZuZfdHM/gPcnJ13pZm9YmZzzexfZrZV7jUu\n",
       "MLMTs593NbMXzewbZjbDzF42s0Pr+TspaIjIoGaGF3Xr7Xu7+8HAf4F93H0V4A/ZQ7sAWwB7ZPf/\n",
       "AmwCrAE8AFyafxno9N7jgdHAOsDhwJlmNqa3ZeurwRQ0Vmh0AVqdZi8XS/VZnEFUl6Vuqknu/pa7\n",
       "LwJw9wvc/U13XwKkwDvNbJUKzwNYAvzA3Ze5+w3AfGDzehQeBlfQUEtDRFrFC6UfzGyYmZ1iZs+Y\n",
       "2evQPqBnXJXnznb3ttz9BcCoASpnF4MpaHyg0QVoda3ab9ysVJ/F6U9dumNF3fpahB6OfQ7YF9jd\n",
       "3ccAG2bHrcr5DdVymfsuhi2BtuUBvmfGDkRi6SngWeA54A2tSSUiDTQD2BioNuR2FLAIeM3MVgZO\n",
       "LnvcqDL6qhFaP2js8+WXuO68dbN7u2W3vMVmzAZeBWbnbq8Csyrd3FlUj6I3m0HUb9wUVJ/FafG6\n",
       "/BHwKzP7MXASXVsNFxEJ8ZeIa9P3gSNzj5cnwhv6Jbj1J/dNAm447XYmH7NTgS89j44gMh14Gngy\n",
       "uz3izpwC30tE+qHZJ/c10kBM7hscQQPaWLzSnUyf+BazNx/FaxuN4o31V2P++DVYuOoIFo2GRWNg\n",
       "4RhYshIFtPSmAVOA+4C7gbvcWdjfF2007f9QLNVncXraT0NBo7KBCBqt3z0VhjFiwU5scCdscGf3\n",
       "Z7q1sWzEQpastJjFo5axcEwbC1c13lptORaMG8GCcSuwYNww5q0D89aGN9aDuRtCW6eq2jC77Z/d\n",
       "f8OMq4mx1f90Z9kA/I4iIg03GFoatwAfHNA3ahu+jDfWm8eMbZwXdhjNi9sP54UdYFnFUb7TgSuA\n",
       "C9yZOqDlEhG1NLqh7qkypV/cUlsf2JWYKTmOmFU5FhiT3Ubnfi5mEuCy5Rfx0nte5sFDVubRg9Zk\n",
       "4dhKZ90FnAX8cTB0X4k0IwWN6hQ0yvTlF7fURtARRPLBJP/zmsDaxDT9DbN/q2sb9hZPf/RJbjxt\n",
       "PeZsXGlCzkxiGN3ZzTwyS33wxVJ9Fkc5jb5R0ChTrw+LpTYW2ArYBngP0R22UZcTnTZef9tt/Pms\n",
       "RTyz9weB5cvO+C8wCbjYnaUDWug+0EWuWKrP4iho9I2CRplGfVgsNQO2BD4GHAy8vctJS0fezo0/\n",
       "f5z7jtoLWK/s0SeABLi6GYOHSCtR0KhOQaNMM3xYsgCyB/B/wO5dTmgbdgMX33Qf03b/MpFryXsZ\n",
       "OAM43Z03B7qsIoNRM1wHmpWCRplm+7BYahOBbwKfAYbnHlrIolV+ws9ebGPx6K8T+ZO86US31fnu\n",
       "LKlLYStQd0qxVJ/FGWrdU9laWxe7+/rZ/UeAo9z9tp7OLXtMO/c1M098qid+MLAp8Ds6pvuvwMh5\n",
       "J3DcmM9y1NsPI5YSmJl76lrA2cCjZhxiNmjmz4hIAdx960oBoxHU0hhAltr7gF8D7yp76A/M3OpY\n",
       "znr0w0QLo3x01jRivZpL3Vkw4AUVaWHNfh3oi+5aD705Vy2NFuOJTwbeC3wVeD330IGs+djDTLJR\n",
       "bPLXLYDvlD2+IfAbYKYZl5ixXd0KLU3HUtvNUrvFUvtKwa871lLbydLW26e6VZjZsWZ2ZdmxX2a3\n",
       "Q83sMTN7w8yeNbP/6eZ1njez3bOfV8y2gH3NzB4lrjF1o5ZGnVhqawE/AT5f9tBDwFFM8keBrwBf\n",
       "B1ar8BK3Az8FrnenrcLj/S+j+uALVVR9WmqPEaP1ALbwxJ+s8XkG4EnXP3JLbSQwldhy9GJP/Av9\n",
       "LedA6k9Ow1Ir7CLnSS/nhZltADwOjHf3+WY2nNiA6ePEROTH3X2ame0C3ADs5O5TKuQ0pgGHu/st\n",
       "ZnYK8H5gP2JZ9RuB0e6+QYX3V0ujVXni07N8x27AY7mH3gHcziT7DZPsT8DbgG8Rw3LzdgL+BDxh\n",
       "xtFmrF6PcktjWWor0xEwAA4oe/zTltpvLLXNy46vRXwhedRS63IxAT5CBAyAg9XaGBju/l9iz+9P\n",
       "ZIc+CCxw93vc/a/uPi077zbgJmDnGl72U8BJ7j7X3V8Efkkd99tQ0KgzT/xWIsdxLHTKV3wKeIhJ\n",
       "diqT7HxiMuG2xFr7+bkcmxLDdKebcZVZcU1TtTKKVVB9blF2f4/SD5bal4DLgCOI3FneEcDWRMD5\n",
       "cnb+epbabZbavUSrNm+rAspakaU23FI711K71VLbrC+v0eKfzd8TIyoBPkssbIqZ7WVmd5vZbDOb\n",
       "A+wNNX0ZXIfcdrHEpOG60beLBvDEFwOnWmqXAz+n49ujAf8POJRJ9gfgp574IWZ8j8iLHEkscwLx\n",
       "f7c/sL8Zk4HziJnmWuNqcCm/mO9kqa1OTCj9be74bpbaSE+8tExNvnWyhaU2DLiY6t9k3020TAbC\n",
       "vsDh2c9nAR8aoPepqLddSgPgj8DPzGxdoltqezMbCVxFdFdf6+7LzOwaamsxvAKUur3Ifq4btTQa\n",
       "yBP/ryf+SaJFcWPuoRWBQ4CHLLVLmGTj3TkWWB/4GrGHR977iMT5c2Z83YyV+lIe7WldrILqszxo\n",
       "DCO+kf6swrnvyP2c/0a/KfGlo7vybNuXwlViqe1sqX3GUivNVdo/9/Dultr4Xr9mC3823X0WcCtw\n",
       "AfCcuz8JjMhurwJtZrYX0WVYiz8A3zWzsWa2HvF/WzcKGk3AE3+AuBB8gs7f9ozYdP4+S+3xrOvq\n",
       "YSbZDsDWrH3/tUw8fxkrzC2dvzbRcplmxrfMGFXHX0MKUkpgZyp1Gx1M5Yv8drnnb5o7vjUxhLs7\n",
       "3QYNS22EpXaBpXZDlRxJ6byJwG1El0wpsJWv03aapfZLS237Hso0mPyeWDHi9wDuPo/4AvgH4DWi\n",
       "++rasudUS+CnwH+Iofk3El3YdRvRpNFTTSb7g98OOAH4aJXTngL+DnwJGMnCMa9x5iOLmb/2Wqw8\n",
       "Eza5Ed53OoyYv4xbfng2jx50nDtv1OlXkH6w1I4Bfghc5okfYak9DWxS49Mv9MQPzb7JT69yzvPA\n",
       "hArH3wJGe+IV10LLynVadvdMT/wr2fFdiC8rV3ribZba8cCJuaduT3zLrrQlwQJgoif+dHe/VE8G\n",
       "43WgKFpGpMxg/7BkkwOPBg4EKu741IlbG+adW48zt4Kzp8ylbcQvgF+4d5oPIk3EUtuE2I++5N3A\n",
       "/USL04lvpOWJ0ofo6JZ63BPfylLbmfi2X8mvgclEd+a/s+eW1kTb2hN/1FIbReTW3kksh/M34Fxy\n",
       "S+N44pZ9PktdpT/0xE/I8nQH5d5vMdENU809wE6eeLfL51hqyxNJ5Nme+J87PTbIrwP9oSG3Q4wn\n",
       "PjkbP78qMVT3LOimxVAeMADWfAzec85YYub5M2YcZdZpXayOpw+zXS21cWXdI9JHWX32ZtOvH5bd\n",
       "P5qOxOizwPUVnnMWtM/b2cJSW4XOXVPl7vXELwRW8sQ/ROf82LaW2h5ES/ZUomv008SSOJ0+M1m+\n",
       "4ou5Q8dbausQgSavu4AB0ao+p8chv3fzcyIncL2lVtdEunSmoNECPPG3PPFbPfGjieF2hxMXkBOJ\n",
       "b4R5s4EpOK+1H9nt+7DmwzBs6Tis7Uzg77bO/RtYattkk7yiW+wAjgNmAVdl3+ykjyy1FfgMvwVm\n",
       "W2r7Vjnnk5baA9lQ1Gvp/A0dOkYcQczt+XuFl/kH8EjpJYncRHfDWu8F8MRL+9jfn3vsAOBqorup\n",
       "J5sCHyg7djKweYVzS34GXEPMK8gHyMOAq3OJ867GsmPu3meqnicDTt1Tg4Clti0xsmqyJ/5Kdmwk\n",
       "cTGJ/vAlKzpuxrCl8MQnYP072hjz4jDcXsP8QmIC0sW5lz3dE//f+v4mzStrMZxAzMI90xMvnxdR\n",
       "fv4BxFBLgFs98d3KHl+baD2sWGMRTiFyCjNyx14ldpn8LR0B5jhiWYlP0NUCYEw+b2GpvR+4s8K5\n",
       "s4BLiBUKKvlOVqZqngcW0TmI7OCJ35W973BimPghuccP9MSvzB4fBSz1xBdm574OrJyd9zKwXmmm\n",
       "u64D1SmnUUYflu5ZajsSSxOs0seXuBQ4yRN/vMczB6FsbsPJxNyGdehIIC8D9iEuqNOAr2Vzb/LP\n",
       "PQH4QXZ3lie+ZnZ8eWLphx8R827KvUzl7YX38MRvstSmABOzY9d74vtaaocB52fH/gGMJ0ZMlbvd\n",
       "E+80TyPrinyOrsnxL3vi51hqvyUGXJSbQ3SbVnM58Cvgjuz+m8A4T7x9HlH23ucRLQ2Ac4A/A8cQ\n",
       "M6dnEDtljiOWPMl7hyf+MOg60B3lNKRXPPE7gB3pPHu0Q1vZf/+0Lmd8DphsqVW6AA1Klto6ltpZ\n",
       "ltpRRHfRscAOdL6oDieC8UeIC/8xFV5qq1x9rmGprZFb2uM1OgeM04m6fhexWOWlZa91Gx1dUzeU\n",
       "HYfO3Va7UDlgQOeuKKB9XarLyg4vJoaCQgS3SiOq8gHjxgqPT/XE7yQmr90BfCkfMHLvnW/dHkl0\n",
       "u+5OdLWtlT3//RU+m3tWeE+pA80IH+Q88Yezi/4ORL/42rQNP5Sn916day7Yhc3+Mp59j4DlsonE\n",
       "L217BevevwoxbwSilXI8kRAdCn5Gx+9aOdh29d3sG/lc4lv+bDrPyIa4kJ9A12VB/gkck19U0FK7\n",
       "hQgiJd/KPf6T7DUWE3uw4Im/aKk9nr1nPhc1i867RVb7fS4Dvpu7f50nPid77ecstQOJAHoznWeh\n",
       "l3ydmJWcn1MyNXv+pXQNgnmTgSVl5c7bmajPcnsSdQHEN+du3kMKpO6pIcyMscDPWe+uw/jQd2HO\n",
       "RvDnX8OykTfw2X2uZrO/lC4QbcCmnvhzDSzugLPUVoSq+5ccQeQobiDmHlRS6lqaQQSPvFfommB+\n",
       "A/iAJ96p68VSWxN4hgjYF3nih9ADS+0XQHkO6iqiVfRxIr+wiSf+YpXnP0xHC2VfT7zLSK1shFP5\n",
       "0NiHiRFTh9M5oKztiVebK1L+undRvU7nEkFj47LjS4juLs0/6gN1T0mfuDPXnS/y4vsP5YJb53Ht\n",
       "+bBsJMBe/P7PZzNri1KQGAacYantnvXztwRLbUdL7Ue9WCSv2lDORz3xcz3xuUCSO/5s2XmlXESl\n",
       "ZTLyAeMk4lv5xuUBA8ATn0nM0TiACFa1uKn8ZYicylez99uvWsDIHE10nZ0N/KXSCVkC/d6yw5/N\n",
       "WkGX0LFw3oO1BozMv8vuzyCS/ABj6QgYS+hYIXp5Yk0rqTO1NAQAM8bDpefC5z5KaW7ARjfDFz5c\n",
       "fupdxMVoIbFc+0jgZ9kFtWlkS4q/QPS93+uJ97iRlaV2Hp3nHpT8wBNPcud9jFga4zfAX6m2ptM0\n",
       "IkPR2ZPA23NDXguR/b7zc4eu8MQL71K01A4nJvpNB/b2xKfkHtuQ6Na8tocAVf6aHwOuyx36JbAu\n",
       "8Mn2I1GXk4mlNk7Ojv7FE9+nh9eeSIwmu7KWz6ilNg5YrpdBr1+yL2IbETmtLYEH8hMYLbUJwOul\n",
       "LsNC3lOjp6QIsSiczyFGvewMDofuBhP+1dNTu/zxWmrvBhZ44uX7gtRF2WxliKGmXboyshE8pxHf\n",
       "6Kst9DjRE3+wyvusQExQG04kjG+l1IKvHDRST3xSbb9F71hqVxGLA75JzO5+foDeZ11iZnYhKypb\n",
       "aqvROW/xPqK76pftR6IujyTyKqUW3hJgLU/8NSqw1LYhWkYjibWaDvDE77fU1iDyQncQcz5OzV7z\n",
       "KWIkVxuwqyd+R9YltzvRcvt7pQ2tsvcaTqwJNQ74Tq1foiy1bxPDpMeUPbQH0eI6lRhw8Qawvyf+\n",
       "j1pet8f3VdCQIpkxjEhunsRyC0ey2fWw0T/gXefD8KqrPWznid8LYKkdQXwLXwLs44mXd50MOEvt\n",
       "IGLYZ8nORM5huie+IHfennQekQTRNTKHmMB2L/C+aheLCu/7d7pf+ntrT/zRWl6rtyy1VYlv53eX\n",
       "hqO2CkuttOfELUT9TSTmDpVMAd7riS+z1O6hY4vTbwKnlf//ZEObJxPf3ksWAnsBFxKJ+7uJyZCV\n",
       "kvC/IYLKScB62bEveOIXVziXbLTdmdnd9rW5Kpw3ihiZth7RYvtlpfMy5UuwLCT+nvodOBQ0ZECY\n",
       "sT7Rh38YMIxxj8OOp8L4h+cx5r+vsvKs8u/RfydGzRxNx7f2/xDdMW/WreBAhYXzniX6xmcRq4se\n",
       "QkyMe3eFp59BXCx2BW72xF+tcE619/0qMYS2oibY26Ep5Vbmfc4TX5p9c59Jx9bHO2VDyLHUvkHn\n",
       "peFLa2ntQkxy/TbRTfYDuppHbfOWXiByVPlZ6rcSu2p+jRi9tZCYRPkAsbdFaSLjXGIgwMLs99qI\n",
       "2P/kMWIduZMqvN8c4L7sd+hunblZwAb9beUpaEghqu3DbMYWxJLre3V6YK0HXuDL265fw0v/1BP/\n",
       "ViGFrJGldgGdZxvX4lwiL3BitS6PGt73bcRs6FKXygN0BKbfeuL/05fXHYostU8R82QuZRJTSp/N\n",
       "bL7LU1S/+L9C5LJK635dRs9Lj1xBDFbYpZfFfJpo7VxXdvzTRKvpn0TAgBjBVikgLAa28sSfrTAK\n",
       "biaRZzuPjgEWB3jiV/eynJ0oaEghqgWNeIxhxB/wieS/fR20v7PlNT39HywDJpQnR7MhrscRuYCf\n",
       "5LuNKpYh1nA6nRgpdGR3XUaW2u3Qab2innRKdveHpXY18AmeYCpb8P+ICWuzgF1602qRDuWfTUtt\n",
       "Y2Ipky/Q/aKIDxA5p5uIWeaVHOaJX5C97lN0v+BjrW4EHiT+Znpyqid+bPb++eVllgG7e+L/stRO\n",
       "JOZLAVyVbd7WZxpyK4Xobh9md9rc+RGR2v0epdV2rz/HeOQgeOqj83ll4nU4pVFB59OxhMRwsn2q\n",
       "y5xB/CFMAm6w1EYDWGpbW2qVNh/6CfA2Imm9Y3bu5yy1Oyy1H5cteNfTH/4T2fu/Say99NMezu+N\n",
       "g4B3sQXv9cTvJr7Bvl0Bo+/KP5ue+LOe+BHE5+FkOhZtLPf1bKTaGWXHzyGWKNm2FDAy91V4jUqr\n",
       "C0/uoch70n3AeAh4kUjsty/emK0dtz8xx2ZfT7w0CuX3uefuY6mVJ87bWWojLbXDLbVTLbVdix4m\n",
       "r5aG9IkZGxJj83fo9MBaU+5mt+QKNr/+DGIc/VXZI7OI/uYdiTzJpnSd7HYvsfz1GcRolUM88Uug\n",
       "fcROvqXyI6LPOd8FNckTT7PgU23fkEOIro0HPPHFltrwooe/SmNkF8c76JgoeLUnfkD22HLEN/jS\n",
       "roPvzg8Xzr3G14mu2JK3iJZKfmDBc8RKwuWtl8uJGfi7l73stOw1f5Xdd2BDT/w/vfz9HqAjsf8d\n",
       "ooVSPgBgD6Kbdb3c4eeJPMqFpX1L1D0lheiue6ry+Qwn1gv6ETA695ADFzF2WsIxG91Oxwf4a0Ry\n",
       "cmyNb7EQ2N4Tf9BS+yzdL0dRet/vE8n3i6qcM9YTr8tGVL2tT6mu1rq01DYnZu6/RQxRfTH32DuJ\n",
       "Vu1fPPFzqzy/fAOrmz3xD1tqj9GxNMznPPHfZ19OjiBGCT5Ix6ZWd9F5p8JvEsO6zyYGlZzcl2HX\n",
       "ltr/kVs6hZiz8ulSUjz73adQfeXkfwEf9MTbFDSkEH29yJmxBvHHeCSdR5ssZc+vPc32vypfhylv\n",
       "JjFUMa3y+H+IIZjfAvqbRF7qiddtnxAFjeLUqy6zIbGv09F1f7wnfpKl9mEin3YHkU+r2jotW3V4\n",
       "AbGM+5zsMat1+HaF112NaI3n91z/vid+oqU2guhmLe31PosYSr4PHSPQILrjHlDQkKZgxpbAj4GP\n",
       "tR9caRZ8dTNYsctcp4XA7cD3PPF7LLWfAP+XPfYm0WoYld1/lUiWr1XhbV8lJoPdRswiLncj0V2w\n",
       "PFXWVBLJs9QepGML3R2z1Xp7+xrfILan/bFne4QUVLbVidZGaTn5ecRQ8iPpGGK+mJg39WAWBP9I\n",
       "TBYEOMET/6GChjQVMz5IdEPF6KVN/5qtTpKZP34mv/vXVv7q5u2zgLMk9inE3IjjiIv8VXRu5ldy\n",
       "oif+fUttLLEy7DGUNp4KRxO7xa3kiZevFSXShaW2NzHp7mbgqL62DAZKlp95kI5Vhf9IDIcvbVL1\n",
       "TU/857nz8127d3riOypoSCGK7gIwY3Mix/BZdj4Zdv9e7OFx2fXw9N6vEl1Ol7hX3K+htKvc9cDq\n",
       "ucPlm/90Wk3VUtuOziNb9mjEjHRQ91SRVJedZcPPr63w0CPEsjfLcueOI7qBjVgiZU0m8aqG3ErT\n",
       "cedJdz4H7MC/jzuLC26ZyW/vhaf3hlij53fAK2acbdY+Aarj+bE16PvpvJrsaURCD2JuxfSy59xD\n",
       "zAiGmKXb48JZIi3oeirvGf/t8nxLNtS79EVqGLGWVZ+ppSF1Y8byxEzZH9Ix9DHvRrKg4M6i9ufF\n",
       "/hI/ID7wxxAjY1bzxCttzlN6zhrAG574omrniLSyLF9xER37wd8CfKhSd5p13n74YiZxsLqnpGWY\n",
       "sTIxzvxwus7VgEh630Mk9v7mTut+SEUGUDY35UtEfuMkT3xWlfO2pWPi4qtMYpyChvRbvfuNs6VJ\n",
       "dibW2vk4UOn/8lFiEtXNwG3unfaMaGrqhy+O6rJ/suDyCLGg6A1M4iIFDem3Rv5hmrEJMflvb7pu\n",
       "7VmylJg4dSVwnnvVrVmbgi50xVFd9l9+johGT8mgYsY6wAnE6p7VFqN7lViq+l6iFTLVnba6FFCk\n",
       "xSloyKBkxihiqerdiVnh7+jm9OeAs4ilqv8LPKhciEhlChpSiGbvAoh9zDmQmDleafRV3rNEMn0G\n",
       "MRfk/gEuXhfNXp+tRHVZrP5cO5crujAiA8WdGcCvzPg10ep4N7AbkQcpXwRxYzpyI8eYcS0RSF4j\n",
       "1uW5C3hErRGR3lFLQ1peNoT380QAGUMs1z662yeFhcQKpfcQezJMy45NVzCRwUzdUyI5ZqwA7EQs\n",
       "cHgAMZy3N2YTQxMfAl4igsnf3KnrPuciA0VBQwoxWPuNzXg3sXnNatltE2LznNW6e16ZN4mtQ+cR\n",
       "Sfcnstv97nRZwjfed3DWZyOoLoulnIZIN9x5gLjgtzPDiFVB1yZmp3+EWMxtVWCVCi+zMjERsdwi\n",
       "M64h5pCMICYjPgg8BKvXbe8OkXpRS0MkJ5ulPgF4J7FT21rAh4Et+viS84gE/DO52xPAve4s7m95\n",
       "RfpC3VMiAyhrlWwOjCdaIpsRQWRbup870p35RACBaAXdROxSOIMY3eXAMncW9r3kIpUpaEgh1G/c\n",
       "e2a8h5iA+DrRvfUOopWyFfxzHOw2vLvn1+AFOvIns4G5tHd/MWeojPLSZ7NYChpSCP1hFsts+K6w\n",
       "7DFivsgm2W1TYo+QCQW8xXxi9nv57ans3/HEMvJPt/oSK/psFktBQ6SFZN1dGxITEkcR+zdPJC7y\n",
       "44kNqpxIrPe3pQLROrkLeIyYSb+M2JRnCtGCmTlUWiwSFDREBqFs06qNiYT8JsSorvWIXMomwEoF\n",
       "vdVcYpfDqUR32NLsfd8iVhSeQeRyHlGOZXAY0kEDSIFb1XTtP3UBFGsg6zNrraxKtBzytw2JILM2\n",
       "cbEfB6xR0NvOJ2bPjwCeB/4BvAisSASZBcSCkXe781ZB7wnos1kUM9sV2BVIhmzQUEujOPrDLFYz\n",
       "1GcWXDYm8igbEiO0Vga2J4LLFkQXWZHeILbufYlYwn52dnstuz3d29n1zVCXg8mQbmkoaIj0XRZU\n",
       "1gG2yW7jgBWIlsRWwL5Ed9US4G0Fve0C4HpgfToGBDwL/IkYhbZKdhsFLA/8C/izO8sKev8hT0FD\n",
       "RAZUFly2Ii70S4DtgPcSC0S2EXNOViYWi6y282J/PE8k7p8l1gJbRnSTjQBeBm5yZ3auvMOJbrlX\n",
       "3Vk6AOVpaQoaUgh1ARRrKNZnFlzeQ7RaVidaLqsT63yVcjAb9f6VbyW64qtqI5L4s4CRROBaCXgF\n",
       "uIBY3uXl7PbMUG+1aO0pEWkK2dDde7NbF1lQ2Z7IsTxPzIY3YqmWnYmusHm52xrA4USLpjvDiO6z\n",
       "8i60tYHvlh2bacZ1xCKUyxPDmucQSf1bs/LsQixGObmH9x1y1NIQkaZmxkrETPuNiBbEBkTLYnH2\n",
       "73uJQFR+LVhEtDr64y/EkOSVibkzTgxFvoNotWxBtHBucGdOP9+rbtQ9JSJDmhkrEnNYViOCxXRi\n",
       "xNa+RKthbSLhvxnFDUHOayOCSCmv8jxwd3abToxcW5Cd41kZX25UN5mChhRiKPbBDyTVZ3GKqsss\n",
       "Qf4BYn+VNiKp30bkXd4BfCg79VFgx/6+Xw+WEN1zfyaGIi8mgsqKRC7oJWLS5XPZ+WOA14uYva+c\n",
       "hohIDbJv9rdkt26ZsS2RZ5lLzD2x7LYOkYNZGXiSmKH/Hrp2j/VkeeB92a07/yGGQY8HZpvxSHZ8\n",
       "ATEPZlazd7mDAAALm0lEQVTZvzOBqe4s6GV5aqKWhohIP5kxkugeG018Gd+GyLNsT8w5eZ648K9F\n",
       "tGxWYWC6yUrmA9cClwG3E0OT30MMiZ4K9kd1T4mItBAzVgP2JgLLMKLlsg6RaJ9NzInZjo6dJJdR\n",
       "zAKWfwT7pIKG9Jv64Iul+izOUK1LM0YQ+7MsIFYk3oQIJsuIGfOltcXy/26RnVfNK2BrK6chIjLI\n",
       "ZFsC5+e8PJndqsrmwkwEPgPsT+RCjEiq35ndLu9rmdTSEBEZYvpz7RxWdGFERGTwUtCQdtla+1IQ\n",
       "1WdxVJfNQ0FDRERqppyGiMgQo5yGiIjUhYKGtFO/cbFUn8VRXTYPBQ0REalZj0HDzI4xszEWzjOz\n",
       "KWa2Rz0KJ/U1FGfcDiTVZ3FUl82jlpbGF939deAjxFr1BwOnDGipRESkKdUSNEoZ9o8CF7v7I92d\n",
       "LK1L/cbFUn0WR3XZPGoJGveb2U3Eaox/M7PRxNK+IiIyxPQ4T8PMhhG7XD3r7nPNbHVgXXd/qB4F\n",
       "7I7maYiI9N5Az9N4P/BkFjAOBo4HXu/Lm4mISGurJWicDbxpZu8EvgE8A1w0oKWShlC/cbFUn8VR\n",
       "XTaPWoLGUo8+rI8DZ7r7mXTsJCUiIkNILTmN24AbgcOITdZnAVPdfZuBL173lNMQEem9gc5pHAQs\n",
       "IuZrTAfWBX7SlzcTEZHW1mPQcPdXgEuBsWa2D7DQ3ZXTGITUb1ws1WdxVJfNo5ZlRA4EJgOfAg4E\n",
       "7jGzTw10wUREpPnUktN4CPiQu8/M7q8B/MPd31GH8nVLOQ0Rkd4b6JyGEcnvktl0LC0iIiJDSC1B\n",
       "40Zi+ZBDzeww4K/ADQNbLGkE9RsXS/VZHNVl81iuhnO+DewP7AQ4cI67XzOgpRIRkaakPcJFRIaY\n",
       "/lw7q7Y0zGw+0bKoxN19dF/eUEREWlfVnIa7j3L3VarcFDAGIfUbF0v1WRzVZfPQHuEiIlIz5TRE\n",
       "RIaYgZ6nISIiAihoSI76jYul+iyO6rJ5KGiIiEjNlNMQERlilNMQEZG6UNCQduo3Lpbqsziqy+ah\n",
       "oCEiIjVTTkNEZIhRTkNEROpCQUPaqd+4WKrP4qgum4eChoiI1Ew5DRGRIUY5DRERqQsFDWmnfuNi\n",
       "qT6Lo7psHgoaIiJSM+U0RESGGOU0RESkLhQ0pJ36jYul+iyO6rJ5KGiIiEjNlNMQERlilNMQEZG6\n",
       "UNCQduo3Lpbqsziqy+ahoCEiIjVTTkNEZIhRTkNEROpCQUPaqd+4WKrP4qgum4eChoiI1Ew5DRGR\n",
       "IUY5DRERqQsFDWmnfuNiqT6Lo7psHgoaIiJSM+U0RESGGOU0RESkLhQ0pJ36jYul+iyO6rJ5KGiI\n",
       "iEjNlNMQERlilNMQEZG6UNCQduo3Lpbqsziqy+ahoCEiIjVTTkNEZIhRTkNEROpCQUPaqd+4WKrP\n",
       "4qgum4eChoiI1Ew5DRGRIUY5DRERqQsFDWmnfuNiqT6Lo7psHgoaIiJSM+U0RESGGOU0RESkLhQ0\n",
       "pJ36jYul+iyO6rJ5KGiIiEjNlNMQERlilNMQEZG6UNCQduo3Lpbqsziqy+ahoCEiIjVTTkNEZIhR\n",
       "TkNEROpCQUPaqd+4WKrP4qgum4eChoiI1Ew5DRGRIUY5DRERqQsFDWmnfuNiqT6Lo7psHgoaIiJS\n",
       "M+U0RESGGOU0RESkLhQ0pJ36jYul+iyO6rJ5KGiIiEjNlNMQERlilNMQEZG6UNCQduo3Lpbqsziq\n",
       "y+ahoCEiIjVTTkNEZIhRTkNEROpCQUPaqd+4WKrP4qgum4eChoiI1Ew5DRGRIUY5DRERqQsFDWmn\n",
       "fuNiqT6Lo7psHgoaIiJSM+U0RESGGOU0RESkLhQ0pJ36jYul+iyO6rJ5KGiIiEjNlNMQERlilNMQ\n",
       "EZG6UNCQduo3Lpbqsziqy+ahoCEiIjVTTkNEZIhRTkNEROpCQUPaqd+4WKrP4qgum4eChoiI1Ew5\n",
       "DRGRIUY5DRERqYumDRpmtp+Z/cbMLjezDze6PEOB+o2LpfosjuqyeTRt0HD3a939f4AvAwc1ujxD\n",
       "xMRGF2CQUX0WR3XZJAY8aJjZ+WY2w8weLju+p5k9YWZPm9mx3bzE8cAZA1tKyYxtdAEGGdVncVSX\n",
       "TaIeLY3fAXvmD5jZcCIQ7AlsBXzGzLY0s4PN7DQzW8fCj4Eb3H1qHcopIiI9WG6g38Dd/21mE8oO\n",
       "bwc84+7PA5jZ5cB+7n4KcHF27GvA7sBoM9vE3c8Z6LIKExpdgEFmQqMLMIhMaHQBJAx40KhiXeCF\n",
       "3P0XgfflT3D304HTe3ohM2vdMcNNyMwOaXQZBhPVZ3FUl82hUUGjkAu95miIiNRXo0ZPvQSsn7u/\n",
       "PtHaEBGRJtaooHEfsKmZTTCzEcSQ2usaVBYREalRPYbcXgbcCWxmZi+Y2WHuvhT4CvA34DHgCnd/\n",
       "vJevW+uQXanAzJ43s4fMbIqZ3ZMdW83M/m5mT5nZTWamYY5VVBpK3l39mdl3s8/qE2b2kcaUunlV\n",
       "qc9JZvZi9hmdYmZ75R5TfVZhZuub2T/N7FEzeyQbVFTc59PdW+4GDAeeIUZULA9MBbZsdLla6QZM\n",
       "A1YrO3Yq8O3s52OBUxpdzma9ATsD7wIe7qn+iGHlU7PP6oTsszus0b9DM92q1GcCfKPCuarP7uty\n",
       "LWBi9vMo4Elgy6I+n007I7wH7UN23X0JcDmwX4PL1IrKBxLsC1yY/Xwh8PH6Fqd1uPu/gTllh6vV\n",
       "337AZe6+xGOY+TPEZ1gyVeoTun5GQfXZLXef7tncNnefDzxOjFgt5PPZqkGj0pDddRtUllblwM1m\n",
       "dp+ZHZEdG+/uM7KfZwDjG1O0llWt/tah80APfV5r91Uze9DMzst1p6g+a5TNkXsXMJmCPp+tGjQ0\n",
       "N6P/dnT3dwF7AUeb2c75Bz3ararnPqqh/lS3Pfs1sCGx7tQrwM+6OVf1WcbMRgFXAf/r7vPyj/Xn\n",
       "89mqQUNDdvvJ3V/J/p0FXEM0R2eY2VoAZrY2MLNxJWxJ1eqv/PO6XnZMuuHuMz0DnEtHl4nqswdm\n",
       "tjwRMC529z9lhwv5fLZq0NCQ3X4ws5XMbJXs55WBjwAPE3VYmnV7CPCnyq8gVVSrv+uAT5vZCDPb\n",
       "ENgUuKcB5Wsp2YWt5BPEZxRUn90yMwPOAx5z91/kHirk89moGeH94u5Lzaw0ZHc4cJ73csjuEDce\n",
       "uCY+WywHXOruN5nZfcAfzOxw4HngwMYVsbllQ8k/AIwzsxeA7wOnUKH+3P0xM/sDMbx8KXBU9u1Z\n",
       "MhXqMwF2NbOJRFfJNOBIUH3WYEfg88BDZjYlO/ZdCvp8tvR2ryIiUl+t2j0lIiINoKAhIiI1U9AQ\n",
       "EZGaKWiIiEjNFDRERKRmChoiIlIzBQ2RBjGzXc3s+kaXQ6Q3FDRERKRmChoiPTCzz5vZ5GwjoLPN\n",
       "bLiZzTezn2eb3NxsZuOycyea2d3ZyqxXl1ZmNbNNsvOmmtn9ZrYRMdN5lJldaWaPm9kljfw9RWqh\n",
       "oCHSDTPbklhuYYdsVeBlwOeAlYB73X1r4F/EshcAFwHfcvd3EmsllY5fCvzK3ScC7ydWbTVi2er/\n",
       "JTbC2cjMdqzLLybSRy259pRIHe0ObAvcl63VtQKxOmgbcEV2ziXA1WY2GhiTbSgEsdHNldkS1eu4\n",
       "+7UA7r4YIHu9e9z95ez+VGLntDsG/tcS6RsFDZGeXejux+UPmNkJ+btU3n+g0q5z5Rblfl6G/ial\n",
       "yal7SqR7/wA+aWZrAJjZamb2NuJv51PZOZ8F/u3ubwBzzGyn7PjBwK3Zlpsvmtl+2WuMNLMV6/pb\n",
       "iBRE32pEuuHuj5vZ8cBNZjYMWAx8BXgT2C57bAaxpwvEPgVnm9lKwLPAYdnxg4FzzOwH2WscSLRO\n",
       "ylsoWnZampqWRhfpAzOb5+6rNLocIvWm7imRvtG3LRmS1NIQEZGaqaUhIiI1U9AQEZGaKWiIiEjN\n",
       "FDRERKRmChoiIlIzBQ0REanZ/wexsrz+71/3wwAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e0f0670d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = np.array([i[\"train_loss\"] for i in net4.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net4.train_history_])\n",
    "plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(1e-2, 3e-2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  0.018812\u001b[0m  |  \u001b[32m  0.022154\u001b[0m  |     0.849113  |             |  29.0s\n",
      "     2  |    0.020473  |    0.025209  |     0.812136  |             |  29.0s\n",
      "     3  |    0.019222  |    0.025264  |     0.760835  |             |  29.0s\n",
      "     4  |    0.019194  |    0.024649  |     0.778699  |             |  29.0s\n",
      "     5  |    0.019166  |    0.026273  |     0.729505  |             |  29.0s\n",
      "     6  |    0.019100  |    0.024854  |     0.768480  |             |  29.0s\n",
      "     7  |    0.019058  |    0.025589  |     0.744785  |             |  29.0s\n",
      "     8  |    0.019035  |    0.023149  |     0.822286  |             |  29.0s\n",
      "     9  |    0.019007  |    0.025033  |     0.759279  |             |  29.0s\n",
      "    10  |    0.019034  |    0.026089  |     0.729581  |             |  29.0s\n",
      "    11  |    0.018973  |    0.023943  |     0.792437  |             |  29.0s\n",
      "    12  |    0.018957  |    0.023497  |     0.806754  |             |  29.0s\n",
      "    13  |    0.018940  |    0.023053  |     0.821575  |             |  29.1s\n",
      "    14  |    0.018918  |    0.023579  |     0.802327  |             |  29.0s\n",
      "    15  |    0.018862  |    0.023986  |     0.786394  |             |  29.0s\n",
      "    16  |    0.018880  |    0.024328  |     0.776063  |             |  29.0s\n",
      "    17  |  \u001b[94m  0.018809\u001b[0m  |    0.023419  |     0.803170  |             |  29.0s\n",
      "    18  |  \u001b[94m  0.018783\u001b[0m  |    0.023487  |     0.799704  |             |  29.1s\n",
      "    19  |  \u001b[94m  0.018759\u001b[0m  |    0.023470  |     0.799288  |             |  29.0s\n",
      "    20  |  \u001b[94m  0.018743\u001b[0m  |    0.023660  |     0.792185  |             |  29.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=<function tensor4 at 0x7f1e6ff5e1b8>,\n",
       "     batch_iterator_test=<__main__.FlipBatchIterator object at 0x7f1e0f06d5d0>,\n",
       "     batch_iterator_train=<__main__.FlipBatchIterator object at 0x7f1e0f06d290>,\n",
       "     conv1_filter_size=(3, 3), conv1_num_filters=32,\n",
       "     conv2_filter_size=(2, 2), conv2_num_filters=64,\n",
       "     conv3_filter_size=(2, 2), conv3_num_filters=128, dropout1_p=0.1,\n",
       "     dropout2_p=0.2, dropout3_p=0.3, dropout4_p=0.5, dropout5_p=0.5,\n",
       "     eval_size=0.2, hidden4_num_units=500, hidden5_num_units=500,\n",
       "     hidden6_num_units=500, input_shape=(None, 1, 65, 65),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('dropout1', <class 'lasagne.layers.noise.DropoutLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <cla..., <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=20, more_params={},\n",
       "     objective=<class 'lasagne.objectives.Objective'>,\n",
       "     objective_loss_function=<function mse at 0x7f1e62a69b90>,\n",
       "     on_epoch_finished=[<__main__.AdjustVariable object at 0x7f1e0f06d610>, <__main__.AdjustVariable object at 0x7f1e0f06d650>],\n",
       "     on_training_finished=(), output_nonlinearity=None,\n",
       "     output_num_units=37, pool1_ds=(2, 2), pool2_ds=(2, 2),\n",
       "     pool3_ds=(2, 2), regression=True,\n",
       "     update=<function nesterov_momentum at 0x7f1e62a702a8>,\n",
       "     update_learning_rate=<CudaNdarrayType(float32, scalar)>,\n",
       "     update_momentum=<CudaNdarrayType(float32, scalar)>,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(float32, matrix))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4.max_epochs = 20\n",
    "net4.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input             \t(None, 1, 65, 65)   \tproduces    4225 outputs\n",
      "  conv1             \t(None, 32, 63, 63)  \tproduces  127008 outputs\n",
      "  pool1             \t(None, 32, 32, 32)  \tproduces   32768 outputs\n",
      "  conv2             \t(None, 64, 31, 31)  \tproduces   61504 outputs\n",
      "  pool2             \t(None, 64, 16, 16)  \tproduces   16384 outputs\n",
      "  conv3             \t(None, 128, 15, 15) \tproduces   28800 outputs\n",
      "  pool3             \t(None, 128, 8, 8)   \tproduces    8192 outputs\n",
      "  hidden4           \t(None, 500)         \tproduces     500 outputs\n",
      "  hidden5           \t(None, 500)         \tproduces     500 outputs\n",
      "  output            \t(None, 37)          \tproduces      37 outputs\n",
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  0.030455\u001b[0m  |  \u001b[32m  0.026424\u001b[0m  |     1.152568  |             |  94.3s\n",
      "     2  |  \u001b[94m  0.026621\u001b[0m  |  \u001b[32m  0.026080\u001b[0m  |     1.020718  |             |  94.4s\n",
      "     3  |  \u001b[94m  0.026176\u001b[0m  |  \u001b[32m  0.025497\u001b[0m  |     1.026648  |             |  94.4s\n",
      "     4  |  \u001b[94m  0.025378\u001b[0m  |  \u001b[32m  0.024406\u001b[0m  |     1.039802  |             |  94.4s\n",
      "     5  |  \u001b[94m  0.024020\u001b[0m  |  \u001b[32m  0.022804\u001b[0m  |     1.053347  |             |  94.3s\n",
      "     6  |  \u001b[94m  0.022649\u001b[0m  |  \u001b[32m  0.021700\u001b[0m  |     1.043716  |             |  94.2s\n",
      "     7  |  \u001b[94m  0.021762\u001b[0m  |  \u001b[32m  0.020961\u001b[0m  |     1.038214  |             |  94.3s\n",
      "     8  |  \u001b[94m  0.021078\u001b[0m  |  \u001b[32m  0.020414\u001b[0m  |     1.032530  |             |  94.3s\n",
      "     9  |  \u001b[94m  0.020572\u001b[0m  |  \u001b[32m  0.020004\u001b[0m  |     1.028394  |             |  94.4s\n",
      "    10  |  \u001b[94m  0.020218\u001b[0m  |  \u001b[32m  0.019720\u001b[0m  |     1.025255  |             |  94.3s\n",
      "    11  |  \u001b[94m  0.019924\u001b[0m  |  \u001b[32m  0.019467\u001b[0m  |     1.023472  |             |  94.3s\n",
      "    12  |  \u001b[94m  0.019698\u001b[0m  |  \u001b[32m  0.019303\u001b[0m  |     1.020461  |             |  94.4s\n",
      "    13  |  \u001b[94m  0.019486\u001b[0m  |  \u001b[32m  0.019110\u001b[0m  |     1.019684  |             |  94.3s\n",
      "    14  |  \u001b[94m  0.019291\u001b[0m  |  \u001b[32m  0.018894\u001b[0m  |     1.020977  |             |  94.4s\n",
      "    15  |  \u001b[94m  0.019107\u001b[0m  |  \u001b[32m  0.018722\u001b[0m  |     1.020549  |             |  94.4s\n",
      "    16  |  \u001b[94m  0.018943\u001b[0m  |  \u001b[32m  0.018559\u001b[0m  |     1.020721  |             |  94.3s\n",
      "    17  |  \u001b[94m  0.018767\u001b[0m  |  \u001b[32m  0.018410\u001b[0m  |     1.019384  |             |  94.4s\n",
      "    18  |  \u001b[94m  0.018593\u001b[0m  |  \u001b[32m  0.018244\u001b[0m  |     1.019133  |             |  94.2s\n",
      "    19  |  \u001b[94m  0.018445\u001b[0m  |  \u001b[32m  0.018091\u001b[0m  |     1.019599  |             |  94.3s\n",
      "    20  |  \u001b[94m  0.018310\u001b[0m  |  \u001b[32m  0.018000\u001b[0m  |     1.017223  |             |  94.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=<function tensor4 at 0x7f1e6ff5e1b8>,\n",
       "     batch_iterator_test=<__main__.BetterBatcher object at 0x7f1e3edb7f90>,\n",
       "     batch_iterator_train=<__main__.BetterBatcher object at 0x7f1e3edaaf90>,\n",
       "     conv1_filter_size=(3, 3), conv1_num_filters=32,\n",
       "     conv2_filter_size=(2, 2), conv2_num_filters=64,\n",
       "     conv3_filter_size=(2, 2), conv3_num_filters=128, eval_size=0.2,\n",
       "     hidden4_num_units=500, hidden5_num_units=500,\n",
       "     input_shape=(None, 1, 65, 65),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv3', <class..., <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=20, more_params={},\n",
       "     objective=<class 'lasagne.objectives.Objective'>,\n",
       "     objective_loss_function=<function mse at 0x7f1e62a69b90>,\n",
       "     on_epoch_finished=[<__main__.AdjustVariable object at 0x7f1e3edb7d10>, <__main__.AdjustVariable object at 0x7f1e3ed69390>],\n",
       "     on_training_finished=(), output_nonlinearity=None,\n",
       "     output_num_units=37, pool1_ds=(2, 2), pool2_ds=(2, 2),\n",
       "     pool3_ds=(2, 2), regression=True,\n",
       "     update=<function nesterov_momentum at 0x7f1e62a702a8>,\n",
       "     update_learning_rate=<CudaNdarrayType(float32, scalar)>,\n",
       "     update_momentum=<CudaNdarrayType(float32, scalar)>,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(float32, matrix))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net5 = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 65, 65),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_ds=(2, 2),\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_ds=(2, 2),\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_ds=(2, 2),\n",
    "    hidden4_num_units=500, hidden5_num_units=500,\n",
    "    output_num_units=37, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    batch_iterator_train=BetterBatcher(batch_size=256),\n",
    "    batch_iterator_test=BetterBatcher(batch_size=256),\n",
    "    regression=True,\n",
    "    max_epochs=20,\n",
    "    verbose=1,\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "net5.fit(X, y)\n",
    "# with open(\"net5.pickle\", \"wb\") as out:\n",
    "#     pickle.dump(net5, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NeuralNet.train_test_split of NeuralNet(X_tensor_type=<function tensor4 at 0x7f1e6ff5e1b8>,\n",
       "     batch_iterator_test=<__main__.FlipBatchIterator object at 0x7f1e0f06d5d0>,\n",
       "     batch_iterator_train=<__main__.FlipBatchIterator object at 0x7f1e0f06d290>,\n",
       "     conv1_filter_size=(3, 3), conv1_num_filters=32,\n",
       "     conv2_filter_size=(2, 2), conv2_num_filters=64,\n",
       "     conv3_filter_size=(2, 2), conv3_num_filters=128, dropout1_p=0.1,\n",
       "     dropout2_p=0.2, dropout3_p=0.3, dropout4_p=0.5, dropout5_p=0.5,\n",
       "     eval_size=0.2, hidden4_num_units=500, hidden5_num_units=500,\n",
       "     hidden6_num_units=500, input_shape=(None, 1, 65, 65),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('dropout1', <class 'lasagne.layers.noise.DropoutLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <cla..., <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=200, more_params={},\n",
       "     objective=<class 'lasagne.objectives.Objective'>,\n",
       "     objective_loss_function=<function mse at 0x7f1e62a69b90>,\n",
       "     on_epoch_finished=[<__main__.AdjustVariable object at 0x7f1e0f06d610>, <__main__.AdjustVariable object at 0x7f1e0f06d650>],\n",
       "     on_training_finished=(), output_nonlinearity=None,\n",
       "     output_num_units=37, pool1_ds=(2, 2), pool2_ds=(2, 2),\n",
       "     pool3_ds=(2, 2), regression=True,\n",
       "     update=<function nesterov_momentum at 0x7f1e62a702a8>,\n",
       "     update_learning_rate=<CudaNdarrayType(float32, scalar)>,\n",
       "     update_momentum=<CudaNdarrayType(float32, scalar)>,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(float32, matrix))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4.train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input             \t(None, 1, 65, 65)   \tproduces    4225 outputs\n",
      "  conv1             \t(None, 32, 63, 63)  \tproduces  127008 outputs\n",
      "  pool1             \t(None, 32, 32, 32)  \tproduces   32768 outputs\n",
      "  conv2             \t(None, 64, 31, 31)  \tproduces   61504 outputs\n",
      "  pool2             \t(None, 64, 16, 16)  \tproduces   16384 outputs\n",
      "  conv3             \t(None, 128, 15, 15) \tproduces   28800 outputs\n",
      "  pool3             \t(None, 128, 8, 8)   \tproduces    8192 outputs\n",
      "  hidden4           \t(None, 500)         \tproduces     500 outputs\n",
      "  hidden5           \t(None, 500)         \tproduces     500 outputs\n",
      "  output            \t(None, 37)          \tproduces      37 outputs\n"
     ]
    }
   ],
   "source": [
    "with open(\"net3.pickle\") as netpick:\n",
    "    net = pickle.load(netpick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "galaxyIDs = []\n",
    "with open(\"data/all_ones_benchmark.csv\", \"rb\") as fi:\n",
    "        for line in fi:\n",
    "            galaxyIDs.append(line.split(\",\")[0])\n",
    "galaxyIDs = galaxyIDs[1:]\n",
    "with open(\"data/all_ones_benchmark.csv\", \"rb\") as fi:\n",
    "    for line in fi:\n",
    "        headers = line\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "testfiles = sorted(glob.glob(\"data/test*.pickle\"))\n",
    "\n",
    "idsq = galaxyIDs[::-1]\n",
    "with open(\"submission.csv\", \"wb\") as sub:\n",
    "    sub.write(headers.strip() + \"\\n\")\n",
    "    for f in testfiles:\n",
    "        with open(f, \"rb\") as testcases:\n",
    "            cases = pickle.load(testcases)\n",
    "            preds = net3.predict(cases)\n",
    "            \n",
    "        for p in preds:\n",
    "            line = \",\".join([idsq.pop()] + map(str, list(p)))\n",
    "            sub.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = net3.predict(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test.0007.pickle',\n",
       " 'data/test.0000.pickle',\n",
       " 'data/test.0004.pickle',\n",
       " 'data/test.0014.pickle',\n",
       " 'data/test.0001.pickle',\n",
       " 'data/test.0011.pickle',\n",
       " 'data/test.0003.pickle',\n",
       " 'data/test.0009.pickle',\n",
       " 'data/test.0006.pickle',\n",
       " 'data/test.0002.pickle',\n",
       " 'data/test.0005.pickle',\n",
       " 'data/test.0013.pickle',\n",
       " 'data/test.0015.pickle',\n",
       " 'data/test.0012.pickle',\n",
       " 'data/test.0008.pickle',\n",
       " 'data/test.0010.pickle']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0 = preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.50218,0.48703,0.00460537,0.0182489,0.466368,0.124474,0.304471,0.147772,0.306027,0.043855,0.202153,0.192707,0.0241477,0.0718137,0.952946,0.0453883,0.422096,0.0160922,0.0152634,0.00740577,0.0138661,0.0354742,0.00433897,0,0,0.0163904,0.012531,0.0447073,0.114419,0.0572375,0.0219606,0,0.0388576,0.0202118,0.00990688,0.0336776,0.112644'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join([str(max(min(1, x), 0)) for x in p0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dcba'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abcd\"[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idsq = galaxyIDs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test.0007.pickle',\n",
       " 'data/test.0000.pickle',\n",
       " 'data/test.0004.pickle',\n",
       " 'data/test.0014.pickle',\n",
       " 'data/test.0001.pickle',\n",
       " 'data/test.0011.pickle',\n",
       " 'data/test.0003.pickle',\n",
       " 'data/test.0009.pickle',\n",
       " 'data/test.0006.pickle',\n",
       " 'data/test.0002.pickle',\n",
       " 'data/test.0005.pickle',\n",
       " 'data/test.0013.pickle',\n",
       " 'data/test.0015.pickle',\n",
       " 'data/test.0012.pickle',\n",
       " 'data/test.0008.pickle',\n",
       " 'data/test.0010.pickle']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob(\"data/test*.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
