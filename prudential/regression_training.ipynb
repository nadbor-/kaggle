{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier, SGDRegressor, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from persistent_cache import memo, PersistentDict as Perd\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "from scipy.optimize import fmin_powell\n",
    "\n",
    "def eval_wrapper(yhat, y):  \n",
    "    y = np.array(y)\n",
    "    y = y.astype(int)\n",
    "    yhat = np.array(yhat)\n",
    "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
    "    return quadratic_weighted_kappa(yhat, y)\n",
    "\n",
    "#TODO: check which ones are really worth encoding and which can be even dropped (some may contain nonoverlapping values between\n",
    "#test and training sest)\n",
    "categorical = {'Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', \n",
    "               'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', \n",
    "               'InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', \n",
    "               'InsuredInfo_6', 'InsuredInfo_7', 'Insurance_History_1', 'Insurance_History_2', \n",
    "               'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', \n",
    "               'Insurance_History_9', 'Family_Hist_1', 'Medical_History_2', 'Medical_History_3', \n",
    "               'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', \n",
    "               'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', \n",
    "               'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_16', \n",
    "               'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', \n",
    "               'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_25', \n",
    "               'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', \n",
    "               'Medical_History_30', 'Medical_History_31', 'Medical_History_33', 'Medical_History_34', \n",
    "               'Medical_History_35', 'Medical_History_36', 'Medical_History_37', \n",
    "#                'Medical_History_38', \n",
    "               'Medical_History_39', 'Medical_History_40', 'Medical_History_41','Medical_History_1', \n",
    "               'Medical_History_15', 'Medical_History_24', 'Medical_History_32'}\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# create logger\n",
    "logger = logging.getLogger(\"logging_tryout2\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "# formatter = logging.Formatter(\"%(asctime)s;%(levelname)s;%(message)s\")\n",
    "formatter = logging.Formatter(\"%(asctime)s;%(levelname)s;%(message)s\",\n",
    "                              \"%Y-%m-%d %H:%M:%S\")\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "# logger.addHandler(ch)\n",
    "def info(msg):\n",
    "    logger.info(msg.replace(\"\\n\", \"  \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "total = pd.concat([train, test])\n",
    "median = total.median()\n",
    "train.fillna(median, inplace=True)\n",
    "test = test.fillna(median, inplace=True)\n",
    "encoder = LabelEncoder()\n",
    "for f in categorical:\n",
    "    encoder.fit(total[f])\n",
    "    train[f] = encoder.transform(train[f])\n",
    "    test[f] = encoder.transform(test[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = test.columns[1:]\n",
    "categorical_inds = [i for i, col in enumerate(feature_cols) if col in categorical]\n",
    "oh_encoder = OneHotEncoder(categorical_features=categorical_inds)\n",
    "\n",
    "X = np.array(train[test.columns[1:]])\n",
    "y = np.array(train.Response)\n",
    "X_actual_test = np.array(test[feature_cols])\n",
    "\n",
    "oh_encoder.fit(X)\n",
    "X = oh_encoder.transform(X).todense()\n",
    "X_actual_test = oh_encoder.transform(X_actual_test).todense()\n",
    "\n",
    "train_test_folds = list(StratifiedKFold(y, n_folds=6, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@memo(Perd(\"memo/train_predictions\"))\n",
    "def train_predictions(model):\n",
    "    ind2pred = {}\n",
    "    for i, (train, test) in enumerate(train_test_folds):\n",
    "        info((\"fitting fold   \"+str(i+1)+ str(model)[:100]))\n",
    "        model.fit(X[train], y[train])\n",
    "        info((\"fold fitted    \"+str(i+1)+  str(model)[:100]))\n",
    "        preds = model.predict(X[test])\n",
    "        for i, p in zip(test, preds):\n",
    "            ind2pred[i] = p\n",
    "    \n",
    "    return np.array([ind2pred[i] for i in range(len(y))])\n",
    "\n",
    "@memo(Perd(\"memo/test_predictions\"))\n",
    "def test_predictions(model):\n",
    "    model.fit(X, y)\n",
    "    return model.predict(X_actual_test)\n",
    "\n",
    "\n",
    "@memo(Perd(\"memo/stacker_train_predictions\"))\n",
    "def stacker_train_predictions(stacker, base_clfs):\n",
    "    info(\"start stacker --------------------------\")\n",
    "    n = len(y)\n",
    "    stacked_X = np.hstack([X] + [train_predictions(clf).reshape(n, 1) for clf in base_clfs])\n",
    "    info(\"base regressors done\")\n",
    "    ind2pred = {}\n",
    "    for i, (train, test) in enumerate(train_test_folds):\n",
    "        info(\"fitting stacker fold %s   %s\" % (i, str(stacker)))\n",
    "\n",
    "        stacker.fit(stacked_X[train], y[train])\n",
    "        info(\"stacker fitted fold %s    %s \" % (i, str(stacker)))\n",
    "        preds = stacker.predict(stacked_X[test])\n",
    "        for i, p in zip(test, preds):\n",
    "            ind2pred[i] = p\n",
    "    info(\"stacker done =========================\")\n",
    "    return np.array([ind2pred[i] for i in range(len(y))])\n",
    "\n",
    "@memo(Perd(\"memo/lazy_stacker_train_predictions\"))\n",
    "def lazy_stacker_train_predictions(stacker, base_clfs):\n",
    "    info(\"start stacker --------------------------\")\n",
    "    n = len(y)\n",
    "    stacked_X = np.hstack([train_predictions(clf).reshape(n, 1) for clf in base_clfs])\n",
    "    info(\"base regressors done\")\n",
    "    ind2pred = {}\n",
    "    for i, (train, test) in enumerate(train_test_folds):\n",
    "        info(\"fitting stacker fold %s   %s\" % (i, str(stacker)))\n",
    "\n",
    "        stacker.fit(stacked_X[train], y[train])\n",
    "        info(\"stacker fitted fold %s    %s \" % (i, str(stacker)))\n",
    "        preds = stacker.predict(stacked_X[test])\n",
    "        for i, p in zip(test, preds):\n",
    "            ind2pred[i] = p\n",
    "    info(\"stacker done =========================\")\n",
    "    return np.array([ind2pred[i] for i in range(len(y))])\n",
    "\n",
    "\n",
    "@memo(Perd(\"memo/stacker_test_predictions\"))\n",
    "def stacker_test_predictions(stacker, base_clfs):\n",
    "    n = len(y)\n",
    "    stacked_X = np.hstack([X] + [train_predictions(clf).reshape(n, 1) for clf in base_clfs])\n",
    "    stacker.fit(stacked_X, y)\n",
    "    n = X_actual_test.shape[0]\n",
    "    stacked_test_X = np.hstack([X_actual_test] + [test_predictions(clf).reshape(n, 1) for clf in base_clfs])\n",
    "    return stacker.predict(stacked_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(model):\n",
    "    pred = train_predictions(model)\n",
    "    return eval_wrapper(pred, y)\n",
    "\n",
    "def make_predictions(model):\n",
    "    model.fit(X, y)\n",
    "    return model.predict(X_actual_test)\n",
    "\n",
    "def benchmark_stacker(model, base_clfs):\n",
    "    pred = stacker_train_predictions(model, base_clfs)\n",
    "    return eval_wrapper(pred, y)\n",
    "\n",
    "def benchmark_lazy_stacker(model, base_clfs):\n",
    "    pred = lazy_stacker_train_predictions(model, base_clfs)\n",
    "    return eval_wrapper(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbr = lambda: XGBRegressor(objective=\"reg:linear\", min_child_weight=80, subsample=0.85, colsample_bytree=0.30, silent=1, max_depth=9)\n",
    "xgbc = lambda: XGBClassifier(objective=\"reg:linear\", min_child_weight=80, subsample=0.85, colsample_bytree=0.30, silent=1, max_depth=9)\n",
    "rfr = lambda: RandomForestRegressor(n_estimators=400)\n",
    "etr = lambda: ExtraTreesRegressor(n_estimators=400)\n",
    "etc = lambda: ExtraTreesClassifier(n_estimators=400)\n",
    "sgdr = lambda: SGDRegressor()\n",
    "perceptron = lambda: Perceptron()\n",
    "\n",
    "dream_team = lambda: sorted([xgbr(), rfr(),  etr(), sgdr(), LinearRegression(), Perceptron(),\n",
    "              SVR(kernel=\"linear\"), SVR(kernel=\"poly\"), SVR(kernel=\"sigmoid\"),\n",
    "              SVR(kernel=\"rbf\"), LogisticRegression()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp = train_predictions(sgdr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.345 ,  3.595 ,  6.97  ,  7.83  ,  7.21  ,  6.4125,  7.2775,\n",
       "        6.1   ,  7.41  ,  4.8125,  3.2575,  3.5225,  6.53  ,  2.5725,\n",
       "        6.4125,  4.25  ,  7.4975,  7.2725,  2.46  ,  7.7375,  7.5325,\n",
       "        4.7225,  2.49  ,  7.3575,  5.325 ,  6.3525,  5.5375,  7.4825,\n",
       "        5.635 ,  5.4475,  3.67  ,  5.3025,  5.1825,  4.0125,  4.53  ,\n",
       "        5.64  ,  7.4975,  6.61  ,  2.07  ,  3.52  ,  5.5425,  4.3425,\n",
       "        2.9525,  6.9675,  4.2175,  5.9375,  4.6625,  5.83  ,  5.3075,\n",
       "        4.3675,  6.8475,  5.12  ,  5.56  ,  2.3025,  5.6   ,  5.04  ,\n",
       "        5.3225,  5.0275,  7.14  ,  4.88  ,  6.2575,  6.8875,  4.0275,\n",
       "        7.0475,  7.565 ,  4.99  ,  7.1525,  6.99  ,  5.34  ,  5.41  ,\n",
       "        4.8825,  7.7875,  5.9075,  6.1175,  5.9625,  4.465 ,  7.345 ,\n",
       "        6.765 ,  5.3325,  7.0225,  3.28  ,  3.16  ,  4.54  ,  6.2125,\n",
       "        4.125 ,  7.2775,  7.    ,  2.465 ,  5.6875,  7.205 ,  6.1625,\n",
       "        4.51  ,  3.8925,  7.3225,  6.6775,  4.2375,  4.9375,  4.5775,\n",
       "        7.3175,  7.6   ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_offset(data, bin_offset, sv, scorer=eval_wrapper):\n",
    "    # data has the format of pred=0, offset_pred=1, labels=2 in the first dim\n",
    "    data[1, data[0].astype(int)==sv] = data[0, data[0].astype(int)==sv] + bin_offset\n",
    "    score = scorer(data[1], data[2])\n",
    "    return score\n",
    "\n",
    "\n",
    "def optimize_offsets(predictions, y):\n",
    "    # train offsets\n",
    "    offsets = np.ones(num_classes) * -0.5\n",
    "    offset_train_preds = np.vstack((predictions, predictions, y))\n",
    "    \n",
    "    for j in range(num_classes):\n",
    "        train_offset = lambda x: -apply_offset(offset_train_preds, x, j)\n",
    "        offsets[j] = fmin_powell(train_offset, offsets[j], disp=False)  \n",
    "    return offsets\n",
    "\n",
    "def actually_apply_offsets(predictions, offsets):\n",
    "    data = np.vstack((predictions, predictions, -np.ones(len(predictions))))\n",
    "    for j in range(num_classes):\n",
    "        data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j] \n",
    "\n",
    "    final_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)\n",
    "    return final_test_preds\n",
    "\n",
    "def optimized_train_predictions(raw_train_predictions):\n",
    "    n = len(y)\n",
    "    ind2pred = {}\n",
    "    for i, (train, test) in enumerate(train_test_folds):\n",
    "        train_preds = raw_train_predictions[train]\n",
    "        offsets = optimize_offsets(train_preds, y[train])\n",
    "        test_preds = actually_apply_offsets(raw_train_predictions[test], offsets)\n",
    "        for i, p in zip(test, test_preds):\n",
    "            ind2pred[i] = p\n",
    "    return np.array([ind2pred[i] for i in range(len(y))])\n",
    "\n",
    "def benchmark_model_optimized(model):\n",
    "    preds = optimized_train_predictions(train_predictions(model))\n",
    "    return eval_wrapper(preds, y)\n",
    "\n",
    "def benchmark_optimized_stacker(stacker, base_clfs):\n",
    "    preds = stacker_train_predictions(stacker, base_clfs)\n",
    "    opreds = optimized_train_predictions(preds)\n",
    "    return eval_wrapper(opreds, y)\n",
    "\n",
    "def test_predictions(stacker, base_clfs):\n",
    "    train_preds = stacker_train_predictions(stacker, base_clfs)\n",
    "    offsets = optimize_offsets(train_preds, y)\n",
    "    test_preds = stacker_test_predictions(stacker, base_clfs)\n",
    "    final_test_preds = actually_apply_offsets(test_preds, offsets)\n",
    "    return final_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6256505585638826"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_model_optimized(etr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3.587928961545842)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmin_powell(lambda x: x**0, 1, disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fmin_powell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGDRegressor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
