{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier, SGDRegressor, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from joblib import Memory\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "\n",
    "def eval_wrapper(yhat, y):  \n",
    "    y = np.array(y)\n",
    "    y = y.astype(int)\n",
    "    yhat = np.array(yhat)\n",
    "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
    "    return quadratic_weighted_kappa(yhat, y)\n",
    "\n",
    "#TODO: check which ones are really worth encoding and which can be even dropped (some may contain nonoverlapping values between\n",
    "#test and training sest)\n",
    "categorical = {'Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', \n",
    "               'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', \n",
    "               'InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', \n",
    "               'InsuredInfo_6', 'InsuredInfo_7', 'Insurance_History_1', 'Insurance_History_2', \n",
    "               'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', \n",
    "               'Insurance_History_9', 'Family_Hist_1', 'Medical_History_2', 'Medical_History_3', \n",
    "               'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', \n",
    "               'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', \n",
    "               'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_16', \n",
    "               'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', \n",
    "               'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_25', \n",
    "               'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', \n",
    "               'Medical_History_30', 'Medical_History_31', 'Medical_History_33', 'Medical_History_34', \n",
    "               'Medical_History_35', 'Medical_History_36', 'Medical_History_37', \n",
    "#                'Medical_History_38', \n",
    "               'Medical_History_39', 'Medical_History_40', 'Medical_History_41','Medical_History_1', \n",
    "               'Medical_History_15', 'Medical_History_24', 'Medical_History_32'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# create logger\n",
    "logger = logging.getLogger(\"logging_tryout2\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "# formatter = logging.Formatter(\"%(asctime)s;%(levelname)s;%(message)s\")\n",
    "formatter = logging.Formatter(\"%(asctime)s;%(levelname)s;%(message)s\",\n",
    "                              \"%Y-%m-%d %H:%M:%S\")\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "# logger.addHandler(ch)\n",
    "def info(msg):\n",
    "    logger.info(msg[:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "total = pd.concat([train, test])\n",
    "median = total.median()\n",
    "train.fillna(median, inplace=True)\n",
    "test = test.fillna(median, inplace=True)\n",
    "encoder = LabelEncoder()\n",
    "for f in categorical:\n",
    "    encoder.fit(total[f])\n",
    "    train[f] = encoder.transform(train[f])\n",
    "    test[f] = encoder.transform(test[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = test.columns[1:]\n",
    "categorical_inds = [i for i, col in enumerate(feature_cols) if col in categorical]\n",
    "oh_encoder = OneHotEncoder(categorical_features=categorical_inds)\n",
    "\n",
    "X = np.array(train[test.columns[1:]])\n",
    "y = np.array(train.Response)\n",
    "X_actual_test = np.array(test[feature_cols])\n",
    "\n",
    "oh_encoder.fit(X)\n",
    "X = oh_encoder.transform(X).todense()\n",
    "X_actual_test = oh_encoder.transform(X_actual_test).todense()\n",
    "\n",
    "train_test_folds = list(StratifiedKFold(y, n_folds=6, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cache = Memory(cachedir=\"cache/_train\", verbose=0)\n",
    "test_cache = Memory(cachedir=\"cache/test\", verbose=0)\n",
    "\n",
    "@train_cache.cache\n",
    "def train_predictions(model):\n",
    "    ind2pred = {}\n",
    "    for i, (train, test) in enumerate(train_test_folds):\n",
    "        info((\"fitting fold   \"+str(i+1)+ str(model)[:100]))\n",
    "        model.fit(X[train], y[train])\n",
    "        info((\"fold fitted    \"+str(i+1)+  str(model)[:100]))\n",
    "        preds = model.predict(X[test])\n",
    "        for i, p in zip(test, preds):\n",
    "            ind2pred[i] = p\n",
    "    \n",
    "    return np.array([ind2pred[i] for i in range(len(y))])\n",
    "\n",
    "@test_cache.cache\n",
    "def test_predictions(model):\n",
    "    model.fit(X, y)\n",
    "    return model.predict(X_actual_test)\n",
    "\n",
    "\n",
    "stacker_train_cache = Memory(cachedir=\"cache/stacker_train\", verbose=0)\n",
    "stacker_test_cache = Memory(cachedir=\"cache/stacker_test\", verbose=0)\n",
    "\n",
    "@stacker_train_cache.cache\n",
    "def stacker_train_predictions(stacker, base_clfs):\n",
    "    info(\"start stacker --------------------------\")\n",
    "    n = len(y)\n",
    "    stacked_X = np.hstack([X] + [train_predictions(clf).reshape(n, 1) for clf in base_clfs])\n",
    "    info(\"base regressors done\")\n",
    "    ind2pred = {}\n",
    "    for i, (train, test) in enumerate(train_test_folds):\n",
    "        info(\"fitting stacker fold %s   %s\" % (i, str(stacker)))\n",
    "\n",
    "        stacker.fit(stacked_X[train], y[train])\n",
    "        info(\"stacker fitted fold %s    %s \" % (i, str(stacker)))\n",
    "        preds = stacker.predict(stacked_X[test])\n",
    "        for i, p in zip(test, preds):\n",
    "            ind2pred[i] = p\n",
    "    info(\"stacker done =========================\")\n",
    "    return np.array([ind2pred[i] for i in range(len(y))])\n",
    "\n",
    "@stacker_test_cache.cache\n",
    "def stacker_test_predictions(stacker, base_clfs):\n",
    "    n = len(y)\n",
    "    stacked_X = np.hstack([X] + [train_predictions(clf).reshape(n, 1) for clf in base_clfs])\n",
    "    stacker.fit(stacked_X, y)\n",
    "    return stacker.predict(X_actual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(model):\n",
    "    pred = train_predictions(model)\n",
    "    return eval_wrapper(pred, y)\n",
    "\n",
    "def make_predictions(model):\n",
    "    model.fit(X, y)\n",
    "    return model.predict(X_actual_test)\n",
    "\n",
    "def benchmark_stacker(model, base_clfs):\n",
    "    pred = stacker_train_predictions(model, base_clfs)\n",
    "    return eval_wrapper(pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(objective=\"reg:linear\", min_child_weight=80, subsample=0.85, colsample_bytree=0.30, silent=1, max_depth=9)\n",
    "xgbc = XGBClassifier(objective=\"reg:linear\", min_child_weight=80, subsample=0.85, colsample_bytree=0.30, silent=1, max_depth=9)\n",
    "rfr = RandomForestRegressor(n_estimators=400)\n",
    "etr = ExtraTreesRegressor(n_estimators=400)\n",
    "sgdr = SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-01-16 15:49:41;INFO;start stacker\n",
      "INFO:logging_tryout2:start stacker\n",
      "2016-01-16 15:49:41;INFO;fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:51:52;INFO;fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:51:52;INFO;fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:54:03;INFO;fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:54:04;INFO;fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:56:15;INFO;fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:56:15;INFO;fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:58:26;INFO;fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 15:58:27;INFO;fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 16:00:38;INFO;fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 16:00:38;INFO;fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fitting fold   XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 16:02:49;INFO;fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "INFO:logging_tryout2:fold fitted    XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_rat\n",
      "2016-01-16 16:02:50;INFO;base regressors done\n",
      "INFO:logging_tryout2:base regressors done\n",
      "2016-01-16 16:02:50;INFO;fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 16:19:14;INFO;stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 16:19:15;INFO;fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 16:35:38;INFO;stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 16:35:39;INFO;fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 16:52:02;INFO;stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 16:52:03;INFO;fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 17:08:27;INFO;stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 17:08:28;INFO;fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 17:24:56;INFO;stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 17:24:57;INFO;fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:fitting stacker fold  XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 17:41:21;INFO;stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "INFO:logging_tryout2:stacker fitted fold   XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.3,\n",
      "       gamma=0, learning_\n",
      "2016-01-16 17:41:22;INFO;stacker done\n",
      "INFO:logging_tryout2:stacker done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6701.41893506\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [xgbr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benchmark_stacker(xgbc, [xgbr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [LinearRegression()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [SVR(kernel=\"linear\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [SVR(kernel=\"poly\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [SVR(kernel=\"rbf\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [SVR(kernel=\"sigmoid\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [SVR(kernel=\"linear\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [Perceptron()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [SVR(kernel=\"linear\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [rfrg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [rfre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [etrg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [etre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_stacker(xgbc, [sgdr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-45a47e2977fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m benchmark_stacker(xgbc[xgbr, rfre, rfrg, etre, etrg, sgdr, LinearRegression(), Perceptron(),\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                  \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"poly\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                  SVR(kernel=\"rbf\")])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rfre' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark_stacker(xgbc, [xgbr, rfr,  etr, sgdr, LinearRegression(), Perceptron(),\n",
    "                                                 SVR(kernel=\"linear\"), SVR(kernel=\"poly\"), SVR(kernel=\"sigmoid\"),\n",
    "                                                 SVR(kernel=\"rbf\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_predictions = stacker_test_predictions(xgbc[xgbr, rfre, rfrg, etre, etrg, sgdr, LinearRegression(), Perceptron(),\n",
    "                                                 SVR(kernel=\"linear\"), SVR(kernel=\"poly\"), SVR(kernel=\"sigmoid\"),\n",
    "                                                 SVR(kernel=\"rbf\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sub(stacker, base_clfs, filename):\n",
    "    preds = stacker_test_predictions(stacker, base_clfs)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['Id'] = test.Id\n",
    "    df['Response'] = preds\n",
    "\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 36s, sys: 68.8 ms, total: 13min 36s\n",
      "Wall time: 13min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n=10000\n",
    "etr.fit(X[:n], y[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
